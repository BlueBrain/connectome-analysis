{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"connalysis: Functions to analyze connectomes","text":"<p>This package provides a library of general functions to analyze connectomes. Functions are divided into three groups:</p> <ul> <li>Network: Graph theoretic and topological functions of connectomes</li> <li>Modelling: Functions to model (parametrize) the connectivity of connectomes</li> <li>Randomization: Generation of randomized controls of connectomes</li> </ul>"},{"location":"modelling/","title":"Functions for modelling","text":"<p>This page describes functions contained in the <code>modelling</code> module used to  model  or parametrize  the connectivity of connectomes</p>"},{"location":"modelling/#src.connalysis.modelling.modelling.aa_test_func","title":"<code>aa_test_func(adj_matrix, size, **kwargs)</code>","text":"<p>General probability model building, optionally for multiple random subsets of neurons.</p> <p>Parameters:</p> Name Type Description Default <code>adj_matrix</code> <code>array_like</code> <p>Adjacency matrix of the circuit</p> required <code>size</code> <code>int</code> <p>number of neurons</p> required <code>**kwargs</code> <code>dict</code> <p>Extra arguments to pass to function</p> <code>{}</code> <p>Returns:</p> Type Description <code>array_like</code> <p>A new adjacency matrix</p> <p>Examples:</p> <p>A comment explaining this example.</p> <p>adj = np.array([0,1,1],[0,0,1],[0,0,0]) test_func(adj, 3) np.array([[0,0,0],[1,0,0],[1,1,0]])</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If the dataframe is missing information about neurons</p>"},{"location":"modelling/#src.connalysis.modelling.modelling.aa_test_func--notes","title":"Notes","text":"<p>Math comments are not working yet.  This is working now. Still references are not linking to each other from notes to references. [1]_</p> \\[ X(e^{j\\omega } ) = x(n)e^{ - j\\omega n} \\]"},{"location":"modelling/#src.connalysis.modelling.modelling.aa_test_func--see-also","title":"See Also","text":"<p>test_newfunc : A variant of this function</p>"},{"location":"modelling/#src.connalysis.modelling.modelling.aa_test_func--references","title":"References","text":"<p>.. [1] Author A, Author B, \"Title,\" Journal, volume, pages, year.</p> Source code in <code>src/connalysis/modelling/modelling.py</code> <pre><code>def aa_test_func(adj_matrix, size, **kwargs):\n\"\"\"General probability model building, optionally for multiple random subsets of neurons.\n\n    Parameters\n    ----------\n    adj_matrix : array_like\n        Adjacency matrix of the circuit\n    size : int\n        number of neurons\n    **kwargs : dict, optional\n        Extra arguments to pass to function\n\n    Returns\n    -------\n    array_like\n        A new adjacency matrix\n\n    Examples\n    --------\n    A comment explaining this example.\n    &gt; adj = np.array([0,1,1],[0,0,1],[0,0,0])\n    &gt; test_func(adj, 3)\n    np.array([[0,0,0],[1,0,0],[1,1,0]])\n\n    Raises\n    ------\n    KeyError\n        If the dataframe is missing information about neurons\n\n    Notes\n    -----\n    Math comments are not working yet.  This is working now.\n    Still references are not linking to each other from notes to references. [1]_\n\n    $$\n    X(e^{j\\\\omega } ) = x(n)e^{ - j\\\\omega n}\n    $$\n\n    See Also\n    --------\n    test_newfunc : A variant of this function\n\n    References\n    ----------\n    .. [1] Author A, Author B, \"Title,\" Journal, volume, pages, year.\n\n\n    \"\"\"\n</code></pre>"},{"location":"modelling/#src.connalysis.modelling.modelling.conn_prob_2nd_order_model","title":"<code>conn_prob_2nd_order_model(adj, node_properties, **kwargs)</code>","text":"<p>Wrapper function for 2nd-order probability model building to be used within a processing pipeline, optionally for multiple random subsets of neurons.</p> <p>Parameters:</p> Name Type Description Default <code>adj</code> <code>scipy.sparse</code> <p>Sparse (symmetric) adjacency matrix of the circuit</p> required <code>node_properties</code> <code>pandas.DataFrame</code> <p>Data frame with neuron properties</p> required <code>kwargs</code> <code>dict</code> <p>Additional model building settings; see Notes for details</p> <code>{}</code> <p>Returns:</p> Type Description <code>pandas.DataFrame</code> <p>Data frame with model paramters (columns) for different seeds (rows) (No plotting and data/model/figures saving supported)</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If the adjacency matrix is not a square matrix matching the length of the neuron properties table</p> <code>AssertionError</code> <p>If invalid arguments given in kwargs which are internally used by this wrapper (like model_order, ...)</p> <code>AssertionError</code> <p>If model fitting error occurs</p> <code>AssertionError</code> <p>If sample_seeds provided as scalar but is not a positive integer</p> <code>KeyError</code> <p>If name(s) of coordinates not in columns of neuron properties table</p> <code>Warning</code> <p>If sample_seeds provided as list with duplicates</p> <code>Warning</code> <p>If sample_seeds provided but ignored because subsampling not applicable</p>"},{"location":"modelling/#src.connalysis.modelling.modelling.conn_prob_2nd_order_model--notes","title":"Notes","text":"<p>The adjacency matrix encodes connectivity between source (rows) and taget (columns) neurons.</p> <p>The 2nd-order model as defined in [1]_ describes connection probabilities as a function of distance between pre- and post-synaptic neurons. Specifically, we use here an exponential distance-dependent model of the form: $$ p(d) = \\mbox{scale} * exp(-\\mbox{exponent} * d) $$ with <code>d</code> as distance in \\(\\mu m\\), and the model parameters <code>scale</code> defining the connection probability at distance zero, and <code>exponent</code> the exponent of distance-dependent decay in \\(\\mu m^{-1}\\).</p> <p><code>kwargs</code> may contain following (optional) settings:</p> <ul> <li><code>bin_size_um</code> Bin size in um for depth binning (optional; default: 100)</li> <li><code>max_range_um</code> Max. distance range in um to consider (optional; default: full distance range)</li> <li><code>sample_size</code> Size of random subset of neurons to consider (optional; default: no subsampling)</li> <li><code>sample_seeds</code> Integer number of seeds to randomly generate, or list of specific random seeds, for reproducible selection of random subset of neurons (optional)</li> <li><code>meta_seed</code> Meta seed for generating N random seeds, if integer number N of sample_seeds is provided (optional; default: 0)</li> <li><code>coord_names</code> Names of the coordinates (columns in neuron properties table) based on which to compute Euclidean distance (optional; default: [\"x\", \"y\", \"z\"])</li> <li><code>N_split</code> Number of data splits (&gt; 1) to sequentially extract data from, to reduce memory consumption (optional; default: no splitting)</li> </ul>"},{"location":"modelling/#src.connalysis.modelling.modelling.conn_prob_2nd_order_model--see-also","title":"See Also","text":"<p>conn_prob_2nd_order_pathway_model : 2nd-order model building function wrapper for different source/target node populations conn_prob_model : Underlying generic model building function wrapper</p>"},{"location":"modelling/#src.connalysis.modelling.modelling.conn_prob_2nd_order_model--references","title":"References","text":"<p>.. [1] Gal E, Perin R, Markram H, London M, Segev I, \"Neuron Geometry Underlies Universal Network Features in Cortical Microcircuits,\" bioRxiv, doi: https://doi.org/10.1101/656058.</p> Source code in <code>src/connalysis/modelling/modelling.py</code> <pre><code>def conn_prob_2nd_order_model(adj, node_properties, **kwargs):\n\"\"\"Wrapper function for 2nd-order probability model building to be used within a processing pipeline, optionally for multiple random subsets of neurons.\n\n    Parameters\n    ----------\n    adj : scipy.sparse\n        Sparse (symmetric) adjacency matrix of the circuit\n    node_properties : pandas.DataFrame\n        Data frame with neuron properties\n    kwargs : dict, optional\n        Additional model building settings; see Notes for details\n\n    Returns\n    -------\n    pandas.DataFrame\n        Data frame with model paramters (columns) for different seeds (rows)\n        (No plotting and data/model/figures saving supported)\n\n    Raises\n    ------\n    AssertionError\n        If the adjacency matrix is not a square matrix matching the length of the neuron properties table\n    AssertionError\n        If invalid arguments given in kwargs which are internally used by this wrapper (like model_order, ...)\n    AssertionError\n        If model fitting error occurs\n    AssertionError\n        If sample_seeds provided as scalar but is not a positive integer\n    KeyError\n        If name(s) of coordinates not in columns of neuron properties table\n    Warning\n        If sample_seeds provided as list with duplicates\n    Warning\n        If sample_seeds provided but ignored because subsampling not applicable\n\n    Notes\n    -----\n    The adjacency matrix encodes connectivity between source (rows) and taget (columns) neurons.\n\n    The 2nd-order model as defined in [1]_ describes connection probabilities as a function of distance between pre- and post-synaptic neurons. Specifically, we use here an exponential distance-dependent model of the form:\n    $$\n    p(d) = \\mbox{scale} * exp(-\\mbox{exponent} * d)\n    $$\n    with `d` as distance in $\\mu m$, and the model parameters `scale` defining the connection probability at distance zero, and `exponent` the exponent of distance-dependent decay in $\\mu m^{-1}$.\n\n    `kwargs` may contain following (optional) settings:\n\n    - `bin_size_um` Bin size in um for depth binning (optional; default: 100)\n    - `max_range_um` Max. distance range in um to consider (optional; default: full distance range)\n    - `sample_size` Size of random subset of neurons to consider (optional; default: no subsampling)\n    - `sample_seeds` Integer number of seeds to randomly generate, or list of specific random seeds, for reproducible selection of random subset of neurons (optional)\n    - `meta_seed` Meta seed for generating N random seeds, if integer number N of sample_seeds is provided (optional; default: 0)\n    - `coord_names` Names of the coordinates (columns in neuron properties table) based on which to compute Euclidean distance (optional; default: [\"x\", \"y\", \"z\"])\n    - `N_split` Number of data splits (&gt; 1) to sequentially extract data from, to reduce memory consumption (optional; default: no splitting)\n\n    See Also\n    --------\n    conn_prob_2nd_order_pathway_model : 2nd-order model building function wrapper for different source/target node populations\n    conn_prob_model : Underlying generic model building function wrapper\n\n    References\n    ----------\n    .. [1] Gal E, Perin R, Markram H, London M, Segev I, \"Neuron Geometry Underlies Universal Network Features in Cortical Microcircuits,\" bioRxiv, doi: https://doi.org/10.1101/656058.\n\n    \"\"\"\n\n    assert 'model_order' not in kwargs.keys(), f'ERROR: Invalid argument \"model_order\" in kwargs!'\n\n    return conn_prob_model(adj, node_properties, model_order=2, **kwargs)\n</code></pre>"},{"location":"modelling/#src.connalysis.modelling.modelling.conn_prob_2nd_order_pathway_model","title":"<code>conn_prob_2nd_order_pathway_model(adj, node_properties_src, node_properties_tgt, **kwargs)</code>","text":"<p>Wrapper function for 2nd-order probability model building to be used within a processing pipeline for pathways with different source and target node populations, optionally for multiple random subsets of neurons.</p> <p>Parameters:</p> Name Type Description Default <code>adj</code> <code>scipy.sparse</code> <p>Sparse adjacency matrix of the circuit (may be non-symmetric)</p> required <code>node_properties_src</code> <code>pandas.DataFrame</code> <p>Data frame with source neuron properties (corresponding to the rows in adj)</p> required <code>node_properties_tgt</code> <code>pandas.DataFrame</code> <p>Data frame with target neuron properties (corresponding to the columns in adj)</p> required <code>kwargs</code> <code>dict</code> <p>Additional model building settings; see \"See Also\" for details</p> <code>{}</code> <p>Returns:</p> Type Description <code>pandas.DataFrame</code> <p>Data frame with model paramters (columns) for different seeds (rows) (No plotting and data/model/figures saving supported)</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If the rows/columns of the adjacency matrix are not matching the lengths of the source/target neuron properties tables</p> <code>AssertionError</code> <p>If invalid arguments given in kwargs which are internally used by this wrapper (like model_order, ...)</p> <code>AssertionError</code> <p>If model fitting error occurs</p> <code>AssertionError</code> <p>If data splitting selected, which is not supported for pathway model building</p> <code>AssertionError</code> <p>If sample_seeds provided as scalar but is not a positive integer</p> <code>KeyError</code> <p>If name(s) of coordinates not in columns of neuron properties table</p> <code>Warning</code> <p>If sample_seeds provided as list with duplicates</p> <code>Warning</code> <p>If sample_seeds provided but ignored because subsampling not applicable</p>"},{"location":"modelling/#src.connalysis.modelling.modelling.conn_prob_2nd_order_pathway_model--notes","title":"Notes","text":"<p>The adjacency matrix encodes connectivity between source (rows) and taget (columns) neurons.</p> <p>The 2nd-order model as defined in [1]_. See \"See Also\" for details.</p>"},{"location":"modelling/#src.connalysis.modelling.modelling.conn_prob_2nd_order_pathway_model--see-also","title":"See Also","text":"<p>conn_prob_2nd_order_model : Special case of 2nd-order model building function wrapper for same source/target node population; further details to be found here</p>"},{"location":"modelling/#src.connalysis.modelling.modelling.conn_prob_2nd_order_pathway_model--references","title":"References","text":"<p>.. [1] Gal E, Perin R, Markram H, London M, Segev I, \"Neuron Geometry Underlies Universal Network Features in Cortical Microcircuits,\" bioRxiv, doi: https://doi.org/10.1101/656058.</p> Source code in <code>src/connalysis/modelling/modelling.py</code> <pre><code>def conn_prob_2nd_order_pathway_model(adj, node_properties_src, node_properties_tgt, **kwargs):\n\"\"\"Wrapper function for 2nd-order probability model building to be used within a processing pipeline for pathways with different source and target node populations, optionally for multiple random subsets of neurons.\n\n    Parameters\n    ----------\n    adj : scipy.sparse\n        Sparse adjacency matrix of the circuit (may be non-symmetric)\n    node_properties_src : pandas.DataFrame\n        Data frame with source neuron properties (corresponding to the rows in adj)\n    node_properties_tgt : pandas.DataFrame\n        Data frame with target neuron properties (corresponding to the columns in adj)\n    kwargs : dict, optional\n        Additional model building settings; see \"See Also\" for details\n\n    Returns\n    -------\n    pandas.DataFrame\n        Data frame with model paramters (columns) for different seeds (rows)\n        (No plotting and data/model/figures saving supported)\n\n    Raises\n    ------\n    AssertionError\n        If the rows/columns of the adjacency matrix are not matching the lengths of the source/target neuron properties tables\n    AssertionError\n        If invalid arguments given in kwargs which are internally used by this wrapper (like model_order, ...)\n    AssertionError\n        If model fitting error occurs\n    AssertionError\n        If data splitting selected, which is not supported for pathway model building\n    AssertionError\n        If sample_seeds provided as scalar but is not a positive integer\n    KeyError\n        If name(s) of coordinates not in columns of neuron properties table\n    Warning\n        If sample_seeds provided as list with duplicates\n    Warning\n        If sample_seeds provided but ignored because subsampling not applicable\n\n    Notes\n    -----\n    The adjacency matrix encodes connectivity between source (rows) and taget (columns) neurons.\n\n    The 2nd-order model as defined in [1]_. See \"See Also\" for details.\n\n    See Also\n    --------\n    conn_prob_2nd_order_model : Special case of 2nd-order model building function wrapper for same source/target node population; further details to be found here\n\n    References\n    ----------\n    .. [1] Gal E, Perin R, Markram H, London M, Segev I, \"Neuron Geometry Underlies Universal Network Features in Cortical Microcircuits,\" bioRxiv, doi: https://doi.org/10.1101/656058.\n\n    \"\"\"\n\n    assert 'model_order' not in kwargs.keys(), f'ERROR: Invalid argument \"model_order\" in kwargs!'\n\n    return conn_prob_pathway_model(adj, node_properties_src, node_properties_tgt, model_order=2, **kwargs)\n</code></pre>"},{"location":"modelling/#src.connalysis.modelling.modelling.conn_prob_3rd_order_model","title":"<code>conn_prob_3rd_order_model(adj, node_properties, **kwargs)</code>","text":"<p>Wrapper function for 3rd-order probability model building to be used within a processing pipeline, optionally for multiple random subsets of neurons.</p> <p>Parameters:</p> Name Type Description Default <code>adj</code> <code>scipy.sparse</code> <p>Sparse (symmetric) adjacency matrix of the circuit</p> required <code>node_properties</code> <code>pandas.DataFrame</code> <p>Data frame with neuron properties</p> required <code>kwargs</code> <code>dict</code> <p>Additional model building settings; see Notes for details</p> <code>{}</code> <p>Returns:</p> Type Description <code>pandas.DataFrame</code> <p>Data frame with model paramters (columns) for different seeds (rows) (No plotting and data/model/figures saving supported)</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If the adjacency matrix is not a square matrix matching the length of the neuron properties table</p> <code>AssertionError</code> <p>If invalid arguments given in kwargs which are internally used by this wrapper (like model_order, ...)</p> <code>AssertionError</code> <p>If model fitting error occurs</p> <code>AssertionError</code> <p>If sample_seeds provided as scalar but is not a positive integer</p> <code>KeyError</code> <p>If name(s) of coordinates not in columns of neuron properties table</p> <code>Warning</code> <p>If sample_seeds provided as list with duplicates</p> <code>Warning</code> <p>If sample_seeds provided but ignored because subsampling not applicable</p>"},{"location":"modelling/#src.connalysis.modelling.modelling.conn_prob_3rd_order_model--notes","title":"Notes","text":"<p>The adjacency matrix encodes connectivity between source (rows) and taget (columns) neurons.</p> <p>The 3rd-order model as defined in [1]_ describes connection probabilities as a bipolar function of distance between pre- and post-synaptic neurons. Specifically, we use here an bipolar exponential distance-dependent model of the form: $$ p(d, \\Delta depth) = \\mbox{scale}_N * exp(-\\mbox{exponent}_N * d)~\\mbox{if}~\\Delta depth &lt; 0 $$ $$ p(d, \\Delta depth) = \\mbox{scale}_P * exp(-\\mbox{exponent}_P * d)~\\mbox{if}~\\Delta depth &gt; 0 $$ $$ p(d, \\Delta depth) = \\mbox{Average of both}~\\mbox{if}~\\Delta depth = 0 $$ with <code>d</code> as distance in \\(\\mu m\\), \\(\\Delta depth\\) as difference in depth coordinate (arbitrary unit, as only sign is used; post-synaptic neuron below (\\(\\Delta depth &lt; 0\\)) or above (\\(\\Delta depth &gt; 0\\)) pre-synaptic neuron), and the model parameters <code>scale</code> defining the connection probability at distance zero, and <code>exponent</code> the exponent of distance-dependent decay in \\(\\mu m^{-1}\\) for both cases.</p> <p><code>kwargs</code> may contain following (optional) settings:</p> <ul> <li><code>bin_size_um</code> Bin size in um for depth binning (optional; default: 100)</li> <li><code>max_range_um</code> Max. distance range in um to consider (optional; default: full distance range)</li> <li><code>sample_size</code> Size of random subset of neurons to consider (optional; default: no subsampling)</li> <li><code>sample_seeds</code> Integer number of seeds to randomly generate, or list of specific random seeds, for reproducible selection of random subset of neurons (optional)</li> <li><code>meta_seed</code> Meta seed for generating N random seeds, if integer number N of sample_seeds is provided (optional; default: 0)</li> <li><code>coord_names</code> Names of the coordinates (columns in neuron properties table) based on which to compute Euclidean distance (optional; default: [\"x\", \"y\", \"z\"])</li> <li><code>depth_name</code> Name of depth coordinate (column in neuron properties table) to use in 3rd-order (bipolar) model (optional; default: \"depth\")</li> <li><code>N_split</code> Number of data splits (&gt; 1) to sequentially extract data from, to reduce memory consumption (optional; default: no splitting)</li> </ul>"},{"location":"modelling/#src.connalysis.modelling.modelling.conn_prob_3rd_order_model--see-also","title":"See Also","text":"<p>conn_prob_3rd_order_pathway_model : 3rd-order model building function wrapper for different source/target node populations conn_prob_model : Underlying generic model building function wrapper</p>"},{"location":"modelling/#src.connalysis.modelling.modelling.conn_prob_3rd_order_model--references","title":"References","text":"<p>.. [1] Gal E, Perin R, Markram H, London M, Segev I, \"Neuron Geometry Underlies Universal Network Features in Cortical Microcircuits,\" bioRxiv, doi: https://doi.org/10.1101/656058.</p> Source code in <code>src/connalysis/modelling/modelling.py</code> <pre><code>def conn_prob_3rd_order_model(adj, node_properties, **kwargs):\n\"\"\"Wrapper function for 3rd-order probability model building to be used within a processing pipeline, optionally for multiple random subsets of neurons.\n\n    Parameters\n    ----------\n    adj : scipy.sparse\n        Sparse (symmetric) adjacency matrix of the circuit\n    node_properties : pandas.DataFrame\n        Data frame with neuron properties\n    kwargs : dict, optional\n        Additional model building settings; see Notes for details\n\n    Returns\n    -------\n    pandas.DataFrame\n        Data frame with model paramters (columns) for different seeds (rows)\n        (No plotting and data/model/figures saving supported)\n\n    Raises\n    ------\n    AssertionError\n        If the adjacency matrix is not a square matrix matching the length of the neuron properties table\n    AssertionError\n        If invalid arguments given in kwargs which are internally used by this wrapper (like model_order, ...)\n    AssertionError\n        If model fitting error occurs\n    AssertionError\n        If sample_seeds provided as scalar but is not a positive integer\n    KeyError\n        If name(s) of coordinates not in columns of neuron properties table\n    Warning\n        If sample_seeds provided as list with duplicates\n    Warning\n        If sample_seeds provided but ignored because subsampling not applicable\n\n    Notes\n    -----\n    The adjacency matrix encodes connectivity between source (rows) and taget (columns) neurons.\n\n    The 3rd-order model as defined in [1]_ describes connection probabilities as a bipolar function of distance between pre- and post-synaptic neurons. Specifically, we use here an bipolar exponential distance-dependent model of the form:\n    $$\n    p(d, \\Delta depth) = \\mbox{scale}_N * exp(-\\mbox{exponent}_N * d)~\\mbox{if}~\\Delta depth &lt; 0\n    $$\n    $$\n    p(d, \\Delta depth) = \\mbox{scale}_P * exp(-\\mbox{exponent}_P * d)~\\mbox{if}~\\Delta depth &gt; 0\n    $$\n    $$\n    p(d, \\Delta depth) = \\mbox{Average of both}~\\mbox{if}~\\Delta depth = 0\n    $$\n    with `d` as distance in $\\mu m$, $\\Delta depth$ as difference in depth coordinate (arbitrary unit, as only sign is used; post-synaptic neuron below ($\\Delta depth &lt; 0$) or above ($\\Delta depth &gt; 0$) pre-synaptic neuron), and the model parameters `scale` defining the connection probability at distance zero, and `exponent` the exponent of distance-dependent decay in $\\mu m^{-1}$ for both cases.\n\n    `kwargs` may contain following (optional) settings:\n\n    - `bin_size_um` Bin size in um for depth binning (optional; default: 100)\n    - `max_range_um` Max. distance range in um to consider (optional; default: full distance range)\n    - `sample_size` Size of random subset of neurons to consider (optional; default: no subsampling)\n    - `sample_seeds` Integer number of seeds to randomly generate, or list of specific random seeds, for reproducible selection of random subset of neurons (optional)\n    - `meta_seed` Meta seed for generating N random seeds, if integer number N of sample_seeds is provided (optional; default: 0)\n    - `coord_names` Names of the coordinates (columns in neuron properties table) based on which to compute Euclidean distance (optional; default: [\"x\", \"y\", \"z\"])\n    - `depth_name` Name of depth coordinate (column in neuron properties table) to use in 3rd-order (bipolar) model (optional; default: \"depth\")\n    - `N_split` Number of data splits (&gt; 1) to sequentially extract data from, to reduce memory consumption (optional; default: no splitting)\n\n    See Also\n    --------\n    conn_prob_3rd_order_pathway_model : 3rd-order model building function wrapper for different source/target node populations\n    conn_prob_model : Underlying generic model building function wrapper\n\n    References\n    ----------\n    .. [1] Gal E, Perin R, Markram H, London M, Segev I, \"Neuron Geometry Underlies Universal Network Features in Cortical Microcircuits,\" bioRxiv, doi: https://doi.org/10.1101/656058.\n\n    \"\"\"\n\n    assert 'model_order' not in kwargs.keys(), f'ERROR: Invalid argument \"model_order\" in kwargs!'\n\n    return conn_prob_model(adj, node_properties, model_order=3, **kwargs)\n</code></pre>"},{"location":"modelling/#src.connalysis.modelling.modelling.conn_prob_3rd_order_pathway_model","title":"<code>conn_prob_3rd_order_pathway_model(adj, node_properties_src, node_properties_tgt, **kwargs)</code>","text":"<p>Wrapper function for 3rd-order probability model building to be used within a processing pipeline for pathways with different source and target node populations, optionally for multiple random subsets of neurons.</p> <p>Parameters:</p> Name Type Description Default <code>adj</code> <code>scipy.sparse</code> <p>Sparse adjacency matrix of the circuit (may be non-symmetric)</p> required <code>node_properties_src</code> <code>pandas.DataFrame</code> <p>Data frame with source neuron properties (corresponding to the rows in adj)</p> required <code>node_properties_tgt</code> <code>pandas.DataFrame</code> <p>Data frame with target neuron properties (corresponding to the columns in adj)</p> required <code>kwargs</code> <code>dict</code> <p>Additional model building settings; see \"See Also\" for details</p> <code>{}</code> <p>Returns:</p> Type Description <code>pandas.DataFrame</code> <p>Data frame with model paramters (columns) for different seeds (rows) (No plotting and data/model/figures saving supported)</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If the rows/columns of the adjacency matrix are not matching the lengths of the source/target neuron properties tables</p> <code>AssertionError</code> <p>If invalid arguments given in kwargs which are internally used by this wrapper (like model_order, ...)</p> <code>AssertionError</code> <p>If model fitting error occurs</p> <code>AssertionError</code> <p>If data splitting selected, which is not supported for pathway model building</p> <code>AssertionError</code> <p>If sample_seeds provided as scalar but is not a positive integer</p> <code>KeyError</code> <p>If name(s) of coordinates not in columns of neuron properties table</p> <code>Warning</code> <p>If sample_seeds provided as list with duplicates</p> <code>Warning</code> <p>If sample_seeds provided but ignored because subsampling not applicable</p>"},{"location":"modelling/#src.connalysis.modelling.modelling.conn_prob_3rd_order_pathway_model--notes","title":"Notes","text":"<p>The adjacency matrix encodes connectivity between source (rows) and taget (columns) neurons.</p> <p>The 3rd-order model as defined in [1]_. See \"See Also\" for details.</p>"},{"location":"modelling/#src.connalysis.modelling.modelling.conn_prob_3rd_order_pathway_model--see-also","title":"See Also","text":"<p>conn_prob_3rd_order_model : Special case of 3rd-order model building function wrapper for same source/target node population; further details to be found here</p>"},{"location":"modelling/#src.connalysis.modelling.modelling.conn_prob_3rd_order_pathway_model--references","title":"References","text":"<p>.. [1] Gal E, Perin R, Markram H, London M, Segev I, \"Neuron Geometry Underlies Universal Network Features in Cortical Microcircuits,\" bioRxiv, doi: https://doi.org/10.1101/656058.</p> Source code in <code>src/connalysis/modelling/modelling.py</code> <pre><code>def conn_prob_3rd_order_pathway_model(adj, node_properties_src, node_properties_tgt, **kwargs):\n\"\"\"Wrapper function for 3rd-order probability model building to be used within a processing pipeline for pathways with different source and target node populations, optionally for multiple random subsets of neurons.\n\n    Parameters\n    ----------\n    adj : scipy.sparse\n        Sparse adjacency matrix of the circuit (may be non-symmetric)\n    node_properties_src : pandas.DataFrame\n        Data frame with source neuron properties (corresponding to the rows in adj)\n    node_properties_tgt : pandas.DataFrame\n        Data frame with target neuron properties (corresponding to the columns in adj)\n    kwargs : dict, optional\n        Additional model building settings; see \"See Also\" for details\n\n    Returns\n    -------\n    pandas.DataFrame\n        Data frame with model paramters (columns) for different seeds (rows)\n        (No plotting and data/model/figures saving supported)\n\n    Raises\n    ------\n    AssertionError\n        If the rows/columns of the adjacency matrix are not matching the lengths of the source/target neuron properties tables\n    AssertionError\n        If invalid arguments given in kwargs which are internally used by this wrapper (like model_order, ...)\n    AssertionError\n        If model fitting error occurs\n    AssertionError\n        If data splitting selected, which is not supported for pathway model building\n    AssertionError\n        If sample_seeds provided as scalar but is not a positive integer\n    KeyError\n        If name(s) of coordinates not in columns of neuron properties table\n    Warning\n        If sample_seeds provided as list with duplicates\n    Warning\n        If sample_seeds provided but ignored because subsampling not applicable\n\n    Notes\n    -----\n    The adjacency matrix encodes connectivity between source (rows) and taget (columns) neurons.\n\n    The 3rd-order model as defined in [1]_. See \"See Also\" for details.\n\n    See Also\n    --------\n    conn_prob_3rd_order_model : Special case of 3rd-order model building function wrapper for same source/target node population; further details to be found here\n\n    References\n    ----------\n    .. [1] Gal E, Perin R, Markram H, London M, Segev I, \"Neuron Geometry Underlies Universal Network Features in Cortical Microcircuits,\" bioRxiv, doi: https://doi.org/10.1101/656058.\n\n    \"\"\"\n\n    assert 'model_order' not in kwargs.keys(), f'ERROR: Invalid argument \"model_order\" in kwargs!'\n\n    return conn_prob_pathway_model(adj, node_properties_src, node_properties_tgt, model_order=3, **kwargs)\n</code></pre>"},{"location":"modelling/#src.connalysis.modelling.modelling.conn_prob_model","title":"<code>conn_prob_model(adj, node_properties, **kwargs)</code>","text":"<p>Wrapper function for generic probability model building to be used within a processing pipeline, optionally for multiple random subsets of neurons.</p> <p>Parameters:</p> Name Type Description Default <code>adj</code> <code>scipy.sparse</code> <p>Sparse (symmetric) adjacency matrix of the circuit</p> required <code>node_properties</code> <code>pandas.DataFrame</code> <p>Data frame with neuron properties</p> required <code>kwargs</code> <code>dict</code> <p>Additional model building settings; see Notes for details</p> <code>{}</code> <p>Returns:</p> Type Description <code>pandas.DataFrame</code> <p>Data frame with model paramters (columns) for different seeds (rows) (No plotting and data/model/figures saving supported)</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If the adjacency matrix is not a square matrix matching the length of the neuron properties table</p> <code>AssertionError</code> <p>If invalid arguments given in kwargs which are internally used by this wrapper</p> <code>AssertionError</code> <p>If model fitting error occurs</p> <code>AssertionError</code> <p>If sample_seeds provided as scalar but is not a positive integer</p> <code>AssertionError</code> <p>If model order not supported (supported: 2, 3)</p> <code>KeyError</code> <p>If model order not provided</p> <code>KeyError</code> <p>If name(s) of coordinates not in columns of neuron properties table</p> <code>Warning</code> <p>If sample_seeds provided as list with duplicates</p> <code>Warning</code> <p>If sample_seeds provided but ignored because subsampling not applicable</p>"},{"location":"modelling/#src.connalysis.modelling.modelling.conn_prob_model--notes","title":"Notes","text":"<p>The adjacency matrix encodes connectivity between source (rows) and taget (columns) neurons.</p> <p>The 2nd-order and 3rd-order models as defined in [1]_ are supported. See \"See Also\" for details.</p> <p><code>kwargs</code> may contain following settings, most of which are optional:</p> <ul> <li><code>model_order</code> Model order (2 or 3)</li> <li><code>bin_size_um</code> Bin size in um for depth binning (optional; default: 100)</li> <li><code>max_range_um</code> Max. distance range in um to consider (optional; default: full distance range)</li> <li><code>sample_size</code> Size of random subset of neurons to consider (optional; default: no subsampling)</li> <li><code>sample_seeds</code> Integer number of seeds to randomly generate, or list of specific random seeds, for reproducible selection of random subset of neurons (optional)</li> <li><code>meta_seed</code> Meta seed for generating N random seeds, if integer number N of sample_seeds is provided (optional; default: 0)</li> <li><code>coord_names</code> Names of the coordinates (columns in neuron properties table) based on which to compute Euclidean distance (optional; default: [\"x\", \"y\", \"z\"])</li> <li><code>depth_name</code> Name of depth coordinate (column in neuron properties table) to use in 3rd-order (bipolar) model (optional; default: \"depth\")</li> <li><code>N_split</code> Number of data splits (&gt; 1) to sequentially extract data from, to reduce memory consumption (optional; default: no splitting)</li> </ul>"},{"location":"modelling/#src.connalysis.modelling.modelling.conn_prob_model--see-also","title":"See Also","text":"<p>conn_prob_2nd_order_model : 2nd-order model building function wrapper for same source/target node population conn_prob_3rd_order_model : 3rd-order model building function wrapper for same source/target node population conn_prob_pathway_model : Generic model building function wrapper for differet source/target node populations</p>"},{"location":"modelling/#src.connalysis.modelling.modelling.conn_prob_model--references","title":"References","text":"<p>.. [1] Gal E, Perin R, Markram H, London M, Segev I, \"Neuron Geometry Underlies Universal Network Features in Cortical Microcircuits,\" bioRxiv, doi: https://doi.org/10.1101/656058.</p> Source code in <code>src/connalysis/modelling/modelling.py</code> <pre><code>def conn_prob_model(adj, node_properties, **kwargs):\n\"\"\"Wrapper function for generic probability model building to be used within a processing pipeline, optionally for multiple random subsets of neurons.\n\n    Parameters\n    ----------\n    adj : scipy.sparse\n        Sparse (symmetric) adjacency matrix of the circuit\n    node_properties : pandas.DataFrame\n        Data frame with neuron properties\n    kwargs : dict, optional\n        Additional model building settings; see Notes for details\n\n    Returns\n    -------\n    pandas.DataFrame\n        Data frame with model paramters (columns) for different seeds (rows)\n        (No plotting and data/model/figures saving supported)\n\n    Raises\n    ------\n    AssertionError\n        If the adjacency matrix is not a square matrix matching the length of the neuron properties table\n    AssertionError\n        If invalid arguments given in kwargs which are internally used by this wrapper\n    AssertionError\n        If model fitting error occurs\n    AssertionError\n        If sample_seeds provided as scalar but is not a positive integer\n    AssertionError\n        If model order not supported (supported: 2, 3)\n    KeyError\n        If model order not provided\n    KeyError\n        If name(s) of coordinates not in columns of neuron properties table\n    Warning\n        If sample_seeds provided as list with duplicates\n    Warning\n        If sample_seeds provided but ignored because subsampling not applicable\n\n    Notes\n    -----\n    The adjacency matrix encodes connectivity between source (rows) and taget (columns) neurons.\n\n    The 2nd-order and 3rd-order models as defined in [1]_ are supported. See \"See Also\" for details.\n\n    `kwargs` may contain following settings, most of which are optional:\n\n    - `model_order` Model order (2 or 3)\n    - `bin_size_um` Bin size in um for depth binning (optional; default: 100)\n    - `max_range_um` Max. distance range in um to consider (optional; default: full distance range)\n    - `sample_size` Size of random subset of neurons to consider (optional; default: no subsampling)\n    - `sample_seeds` Integer number of seeds to randomly generate, or list of specific random seeds, for reproducible selection of random subset of neurons (optional)\n    - `meta_seed` Meta seed for generating N random seeds, if integer number N of sample_seeds is provided (optional; default: 0)\n    - `coord_names` Names of the coordinates (columns in neuron properties table) based on which to compute Euclidean distance (optional; default: [\"x\", \"y\", \"z\"])\n    - `depth_name` Name of depth coordinate (column in neuron properties table) to use in 3rd-order (bipolar) model (optional; default: \"depth\")\n    - `N_split` Number of data splits (&gt; 1) to sequentially extract data from, to reduce memory consumption (optional; default: no splitting)\n\n    See Also\n    --------\n    conn_prob_2nd_order_model : 2nd-order model building function wrapper for same source/target node population\n    conn_prob_3rd_order_model : 3rd-order model building function wrapper for same source/target node population\n    conn_prob_pathway_model : Generic model building function wrapper for differet source/target node populations\n\n    References\n    ----------\n    .. [1] Gal E, Perin R, Markram H, London M, Segev I, \"Neuron Geometry Underlies Universal Network Features in Cortical Microcircuits,\" bioRxiv, doi: https://doi.org/10.1101/656058.\n\n    \"\"\"\n\n    assert adj.shape[0] == adj.shape[1] == node_properties.shape[0], 'ERROR: Data size mismatch!'\n\n    invalid_args = ['model_name', 'sample_seed', 'model_dir', 'data_dir', 'plot_dir', 'do_plot', 'part_idx'] # Not allowed arguments, as they will be set/used internally\n    for arg in invalid_args:\n        assert arg not in kwargs.keys(), f'ERROR: Invalid argument \"{arg}\" in kwargs!'\n    kwargs.update({'model_dir': None, 'data_dir': None, 'plot_dir': None, 'do_plot': False, 'part_idx': None}) # Disable plotting/saving\n    model_name = None\n    model_order = kwargs.pop('model_order')\n\n    sample_size = kwargs.get('sample_size')\n    if sample_size is None or sample_size &lt;= 0 or sample_size &gt;= node_properties.shape[0]:\n        sample_seeds = [None] # No randomization\n        if kwargs.pop('sample_seeds', None) is not None:\n            logging.warning('Using all neurons, ignoring sample seeds!')\n    else:\n        sample_seeds = kwargs.pop('sample_seeds', 1)\n\n        if not isinstance(sample_seeds, list): # sample_seeds corresponds to number of seeds to generate\n            sample_seeds = _generate_seeds(sample_seeds, meta_seed=kwargs.pop('meta_seed', 0))\n        else:\n            num_seeds = len(sample_seeds)\n            sample_seeds = list(np.unique(sample_seeds)) # Assure that unique and sorted\n            if len(sample_seeds) &lt; num_seeds:\n                logging.warning(f'Duplicate seeds provided!')\n\n    model_params = pd.DataFrame()\n    for seed in sample_seeds:\n        kwargs.update({'sample_seed': seed})\n        _, model_dict = run_model_building(adj, node_properties, model_name, model_order, **kwargs)\n        model_params = pd.concat([model_params, pd.DataFrame(model_dict['model_params'], index=pd.Index([seed], name='seed'))])\n\n    return model_params\n</code></pre>"},{"location":"modelling/#src.connalysis.modelling.modelling.conn_prob_pathway_model","title":"<code>conn_prob_pathway_model(adj, node_properties_src, node_properties_tgt, **kwargs)</code>","text":"<p>Wrapper function for generic probability model building to be used within a processing pipeline for pathways with different source and target node populations, optionally for multiple random subsets of neurons.</p> <p>Parameters:</p> Name Type Description Default <code>adj</code> <code>scipy.sparse</code> <p>Sparse adjacency matrix of the circuit (may be non-symmetric)</p> required <code>node_properties_src</code> <code>pandas.DataFrame</code> <p>Data frame with source neuron properties (corresponding to the rows in adj)</p> required <code>node_properties_tgt</code> <code>pandas.DataFrame</code> <p>Data frame with target neuron properties (corresponding to the columns in adj)</p> required <code>kwargs</code> <code>dict</code> <p>Additional model building settings; see \"See Also\" for details</p> <code>{}</code> <p>Returns:</p> Type Description <code>pandas.DataFrame</code> <p>Data frame with model paramters (columns) for different seeds (rows) (No plotting and data/model/figures saving supported)</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If the rows/columns of the adjacency matrix are not matching the lengths of the source/target neuron properties tables</p> <code>AssertionError</code> <p>If invalid arguments given in kwargs which are internally used by this wrapper</p> <code>AssertionError</code> <p>If model fitting error occurs</p> <code>AssertionError</code> <p>If sample_seeds provided as scalar but is not a positive integer</p> <code>AssertionError</code> <p>If model order not supported (supported: 2, 3)</p> <code>AssertionError</code> <p>If data splitting selected, which is not supported for pathway model building</p> <code>KeyError</code> <p>If model order not provided</p> <code>KeyError</code> <p>If name(s) of coordinates not in columns of neuron properties table</p> <code>Warning</code> <p>If sample_seeds provided as list with duplicates</p> <code>Warning</code> <p>If sample_seeds provided but ignored because subsampling not applicable</p>"},{"location":"modelling/#src.connalysis.modelling.modelling.conn_prob_pathway_model--notes","title":"Notes","text":"<p>The adjacency matrix encodes connectivity between source (rows) and taget (columns) neurons.</p> <p>The 2nd-order and 3rd-order models as defined in [1]_ are supported. See \"See Also\" for details.</p>"},{"location":"modelling/#src.connalysis.modelling.modelling.conn_prob_pathway_model--see-also","title":"See Also","text":"<p>conn_prob_model : Special case of generic model building function wrapper for same source/target node population; further details to be found here conn_prob_2nd_order_pathway_model : 2nd-order model building function wrapper for different source/target node population conn_prob_3rd_order_pathway_model : 3rd-order model building function wrapper for different source/target node population</p>"},{"location":"modelling/#src.connalysis.modelling.modelling.conn_prob_pathway_model--references","title":"References","text":"<p>.. [1] Gal E, Perin R, Markram H, London M, Segev I, \"Neuron Geometry Underlies Universal Network Features in Cortical Microcircuits,\" bioRxiv, doi: https://doi.org/10.1101/656058.</p> Source code in <code>src/connalysis/modelling/modelling.py</code> <pre><code>def conn_prob_pathway_model(adj, node_properties_src, node_properties_tgt, **kwargs):\n\"\"\"Wrapper function for generic probability model building to be used within a processing pipeline for pathways with different source and target node populations, optionally for multiple random subsets of neurons.\n\n    Parameters\n    ----------\n    adj : scipy.sparse\n        Sparse adjacency matrix of the circuit (may be non-symmetric)\n    node_properties_src : pandas.DataFrame\n        Data frame with source neuron properties (corresponding to the rows in adj)\n    node_properties_tgt : pandas.DataFrame\n        Data frame with target neuron properties (corresponding to the columns in adj)\n    kwargs : dict, optional\n        Additional model building settings; see \"See Also\" for details\n\n    Returns\n    -------\n    pandas.DataFrame\n        Data frame with model paramters (columns) for different seeds (rows)\n        (No plotting and data/model/figures saving supported)\n\n    Raises\n    ------\n    AssertionError\n        If the rows/columns of the adjacency matrix are not matching the lengths of the source/target neuron properties tables\n    AssertionError\n        If invalid arguments given in kwargs which are internally used by this wrapper\n    AssertionError\n        If model fitting error occurs\n    AssertionError\n        If sample_seeds provided as scalar but is not a positive integer\n    AssertionError\n        If model order not supported (supported: 2, 3)\n    AssertionError\n        If data splitting selected, which is not supported for pathway model building\n    KeyError\n        If model order not provided\n    KeyError\n        If name(s) of coordinates not in columns of neuron properties table\n    Warning\n        If sample_seeds provided as list with duplicates\n    Warning\n        If sample_seeds provided but ignored because subsampling not applicable\n\n    Notes\n    -----\n    The adjacency matrix encodes connectivity between source (rows) and taget (columns) neurons.\n\n    The 2nd-order and 3rd-order models as defined in [1]_ are supported. See \"See Also\" for details.\n\n    See Also\n    --------\n    conn_prob_model : Special case of generic model building function wrapper for same source/target node population; further details to be found here\n    conn_prob_2nd_order_pathway_model : 2nd-order model building function wrapper for different source/target node population\n    conn_prob_3rd_order_pathway_model : 3rd-order model building function wrapper for different source/target node population\n\n    References\n    ----------\n    .. [1] Gal E, Perin R, Markram H, London M, Segev I, \"Neuron Geometry Underlies Universal Network Features in Cortical Microcircuits,\" bioRxiv, doi: https://doi.org/10.1101/656058.\n\n    \"\"\"\n\n    assert adj.shape[0] == node_properties_src.shape[0] and adj.shape[1] == node_properties_tgt.shape[0], 'ERROR: Data size mismatch!'\n\n    invalid_args = ['model_name', 'sample_seed', 'model_dir', 'data_dir', 'plot_dir', 'do_plot', 'part_idx'] # Not allowed arguments, as they will be set/used internally\n    for arg in invalid_args:\n        assert arg not in kwargs.keys(), f'ERROR: Invalid argument \"{arg}\" in kwargs!'\n    kwargs.update({'model_dir': None, 'data_dir': None, 'plot_dir': None, 'do_plot': False, 'part_idx': None}) # Disable plotting/saving\n    model_name = None\n    model_order = kwargs.pop('model_order')\n\n    sample_size = kwargs.get('sample_size')\n    if sample_size is None  or sample_size &lt;= 0 or sample_size &gt;= np.maximum(node_properties_src.shape[0], node_properties_tgt.shape[0]):\n        sample_seeds = [None] # No randomization\n        if kwargs.pop('sample_seeds', None) is not None:\n            logging.warning('Using all neurons, ignoring sample seeds!')\n    else:\n        sample_seeds = kwargs.pop('sample_seeds', 1)\n\n        if not isinstance(sample_seeds, list): # sample_seeds corresponds to number of seeds to generate\n            sample_seeds = _generate_seeds(sample_seeds, meta_seed=kwargs.pop('meta_seed', 0))\n        else:\n            num_seeds = len(sample_seeds)\n            sample_seeds = list(np.unique(sample_seeds)) # Assure that unique and sorted\n            if len(sample_seeds) &lt; num_seeds:\n                logging.warning(f'Duplicate seeds provided!')\n\n    model_params = pd.DataFrame()\n    for seed in sample_seeds:\n        kwargs.update({'sample_seed': seed})\n        _, model_dict = run_pathway_model_building(adj, node_properties_src, node_properties_tgt, model_name, model_order, **kwargs)\n        model_params = pd.concat([model_params, pd.DataFrame(model_dict['model_params'], index=pd.Index([seed], name='seed'))])\n\n    return model_params\n</code></pre>"},{"location":"modelling/#src.connalysis.modelling.modelling.run_batch_model_building","title":"<code>run_batch_model_building(adj_file, nrn_file, cfg_file, N_split = None, part_idx = None)</code>","text":"<p>Main function for data extraction and model building to be used in a batch script on different data splits.</p> <p>Parameters:</p> Name Type Description Default <code>adj_file</code> <code>str</code> <p>File name (.npz format) of scipy.sparse adjacency matrix of the circuit</p> required <code>nrn_file</code> <code>str</code> <p>File name (.h5 or .feather format) of pandas.DataFrame with neuron properties</p> required <code>cfg_file</code> <code>str</code> <p>File name (.json format) of config dict specifying the model building operation; see Notes for details</p> required <code>N_split</code> <code>int</code> <p>Number of data splits to divide data extraction into (to reduce memory consumption)</p> <code>None</code> <code>part_idx</code> <code>int</code> <p>Index of current data split (part) to extract data from Range:  0 .. N_split - 1 Run data extraction of given data split -1                Merge data splits and build model</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>Nothing returned here; Data/model/figures are written to output directories as specified in <code>cfg_file</code></p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If nrn_file is not in .h5 or .feather format</p> <code>AssertionError</code> <p>If the adjacency matrix is not a square matrix matching the length of the neuron properties table</p> <code>AssertionError</code> <p>If model order not supported (supported: 2, 3)</p> <code>AssertionError</code> <p>If model fitting error occurs</p> <code>KeyError</code> <p>If name(s) of coordinates not in columns of neuron properties table</p>"},{"location":"modelling/#src.connalysis.modelling.modelling.run_batch_model_building--notes","title":"Notes","text":"<p>The adjacency matrix encodes connectivity between source (rows) and taget (columns) neurons.</p> <p><code>cfg_file</code> must be a .json file containing a dictionary with following entries, most of which are optional:</p> <ul> <li><code>model_name</code> Name of the model (to be used in file names, ...)</li> <li><code>model_order</code> Model order (2 or 3)</li> <li><code>bin_size_um</code> Bin size in um for depth binning (optional; default: 100)</li> <li><code>max_range_um</code> Max. distance range in um to consider (optional; default: full distance range)</li> <li><code>sample_size</code> Size of random subset of neurons to consider (optional; default: no subsampling)</li> <li><code>sample_seed</code> Seed for reproducible selection of random subset of neurons (optional)</li> <li><code>coord_names</code> Names of the coordinates (columns in neuron properties table) based on which to compute Euclidean distance (optional; default: [\"x\", \"y\", \"z\"])</li> <li><code>depth_name</code> Name of depth coordinate (column in neuron properties table) to use in 3rd-order (bipolar) model (optional; default: \"depth\")</li> <li><code>model_dir</code> Output directory where to save the model (optional; default: no saving)</li> <li><code>data_dir</code> Output directory where to save the extracted data (optional; default: no saving)</li> <li><code>do_plot</code> Enable/disable output plotting (optional; default: no plotting)</li> <li><code>plot_dir</code> Output directory where to save the plots, if plotting enabled (optional; default: no saving)</li> <li><code>N_split</code> Number of data splits (&gt; 1) to sequentially extract data from, to reduce memory consumption (optional; default: no splitting)</li> <li><code>part_idx</code> Part index (from 0 to N_split-1) to run data extraction only on a specific data split; -1 to merge existing splits and build model (optional; default: data extraction and model building for all splits)</li> </ul>"},{"location":"modelling/#src.connalysis.modelling.modelling.run_batch_model_building--see-also","title":"See Also","text":"<p>run_model_building : Underlying main function for model building</p> Source code in <code>src/connalysis/modelling/modelling.py</code> <pre><code>def run_batch_model_building(adj_file, nrn_file, cfg_file, N_split=None, part_idx=None):\n\"\"\"Main function for data extraction and model building to be used in a batch script on different data splits.\n\n    Parameters\n    ----------\n    adj_file : str\n        File name (.npz format) of scipy.sparse adjacency matrix of the circuit\n    nrn_file : str\n        File name (.h5 or .feather format) of pandas.DataFrame with neuron properties\n    cfg_file : str\n        File name (.json format) of config dict specifying the model building operation; see Notes for details\n    N_split : int, optional\n        Number of data splits to divide data extraction into (to reduce memory consumption)\n    part_idx : int, optional\n        Index of current data split (part) to extract data from\n        Range:  0 .. N_split - 1 Run data extraction of given data split\n               -1                Merge data splits and build model\n\n    Returns\n    -------\n    None\n        Nothing returned here; Data/model/figures are written to output directories as specified in `cfg_file`\n\n    Raises\n    ------\n    AssertionError\n        If nrn_file is not in .h5 or .feather format\n    AssertionError\n        If the adjacency matrix is not a square matrix matching the length of the neuron properties table\n    AssertionError\n        If model order not supported (supported: 2, 3)\n    AssertionError\n        If model fitting error occurs\n    KeyError\n        If name(s) of coordinates not in columns of neuron properties table\n\n    Notes\n    -----\n    The adjacency matrix encodes connectivity between source (rows) and taget (columns) neurons.\n\n    `cfg_file` must be a .json file containing a dictionary with following entries, most of which are optional:\n\n    - `model_name` Name of the model (to be used in file names, ...)\n    - `model_order` Model order (2 or 3)\n    - `bin_size_um` Bin size in um for depth binning (optional; default: 100)\n    - `max_range_um` Max. distance range in um to consider (optional; default: full distance range)\n    - `sample_size` Size of random subset of neurons to consider (optional; default: no subsampling)\n    - `sample_seed` Seed for reproducible selection of random subset of neurons (optional)\n    - `coord_names` Names of the coordinates (columns in neuron properties table) based on which to compute Euclidean distance (optional; default: [\"x\", \"y\", \"z\"])\n    - `depth_name` Name of depth coordinate (column in neuron properties table) to use in 3rd-order (bipolar) model (optional; default: \"depth\")\n    - `model_dir` Output directory where to save the model (optional; default: no saving)\n    - `data_dir` Output directory where to save the extracted data (optional; default: no saving)\n    - `do_plot` Enable/disable output plotting (optional; default: no plotting)\n    - `plot_dir` Output directory where to save the plots, if plotting enabled (optional; default: no saving)\n    - `N_split` Number of data splits (&gt; 1) to sequentially extract data from, to reduce memory consumption (optional; default: no splitting)\n    - `part_idx` Part index (from 0 to N_split-1) to run data extraction only on a specific data split; -1 to merge existing splits and build model (optional; default: data extraction and model building for all splits)\n\n    See Also\n    --------\n    run_model_building : Underlying main function for model building\n\n    \"\"\"\n\n    # Load adjacency matrix (.npz) &amp; neuron properties table (.h5 or .feather)\n    adj = sps.load_npz(adj_file)\n    if os.path.splitext(nrn_file)[-1] == '.h5':\n        node_properties = pd.read_hdf(nrn_file)\n    elif os.path.splitext(nrn_file)[-1] == '.feather':\n        node_properties = pd.read_feather(nrn_file)\n    else:\n        assert False, f'ERROR: Neuron table format \"{os.path.splitext(nrn_file)[-1]}\" not supported!'\n\n    assert adj.shape[0] == adj.shape[1] == node_properties.shape[0], 'ERROR: Data size mismatch!'\n    logging.info(f'Loaded connectivity and properties of {node_properties.shape[0]} neurons')\n\n    # Load config file (.json)\n    with open(cfg_file, 'r') as f:\n        config_dict = json.load(f)\n\n    # Set/Overwrite data split options\n    if N_split is not None:\n        config_dict.update({'N_split': int(N_split)})\n    if part_idx is not None:\n        config_dict.update({'part_idx': int(part_idx)})\n\n    # Run model building\n    run_model_building(adj, node_properties, **config_dict)\n</code></pre>"},{"location":"modelling/#src.connalysis.modelling.modelling.run_model_building","title":"<code>run_model_building(adj, node_properties, model_name, model_order, **kwargs)</code>","text":"<p>Main function for probability model building, consisting of three steps: Data extraction, model fitting, and (optionally) data/model visualization.</p> <p>Parameters:</p> Name Type Description Default <code>adj</code> <code>scipy.sparse</code> <p>Sparse (symmetric) adjacency matrix of the circuit</p> required <code>node_properties</code> <code>pandas.DataFrame</code> <p>Data frame with neuron properties</p> required <code>model_name</code> <code>str</code> <p>Name of the model (to be used in file names, ...)</p> required <code>model_order</code> <code>int</code> <p>Model order (2 or 3)</p> required <code>kwargs</code> <code>dict</code> <p>Additional model building settings; see Notes for details</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict</code> <p>Data dictionary containing extracted data points (connection probabilities) from the \"extract\" step; Data/figures also written to output directories as specified in kwargs</p> <code>dict</code> <p>Model dictionary containing probability model fitted to data points from \"model fitting\" step; Model/figures also written to output directories as specified in kwargs</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If the adjacency matrix is not a square matrix matching the length of the neuron properties table</p> <code>AssertionError</code> <p>If model order not supported (supported: 2, 3)</p> <code>AssertionError</code> <p>If model fitting error occurs</p> <code>KeyError</code> <p>If name(s) of coordinates not in columns of neuron properties table</p>"},{"location":"modelling/#src.connalysis.modelling.modelling.run_model_building--notes","title":"Notes","text":"<p>The adjacency matrix encodes connectivity between source (rows) and taget (columns) neurons.</p> <p>The 2nd-order and 3rd-order models as defined in [1]_ are supported. See \"See Also\" for details.</p> <p><code>kwargs</code> may contain following (optional) settings:</p> <ul> <li><code>bin_size_um</code> Bin size in um for depth binning (optional; default: 100)</li> <li><code>max_range_um</code> Max. distance range in um to consider (optional; default: full distance range)</li> <li><code>sample_size</code> Size of random subset of neurons to consider (optional; default: no subsampling)</li> <li><code>sample_seed</code> Seed for reproducible selection of random subset of neurons (optional)</li> <li><code>coord_names</code> Names of the coordinates (columns in neuron properties table) based on which to compute Euclidean distance (optional; default: [\"x\", \"y\", \"z\"])</li> <li><code>depth_name</code> Name of depth coordinate (column in neuron properties table) to use in 3rd-order (bipolar) model (optional; default: \"depth\")</li> <li><code>model_dir</code> Output directory where to save the model (optional; default: no saving)</li> <li><code>data_dir</code> Output directory where to save the extracted data (optional; default: no saving)</li> <li><code>do_plot</code> Enable/disable output plotting (optional; default: no plotting)</li> <li><code>plot_dir</code> Output directory where to save the plots, if plotting enabled (optional; default: no saving)</li> <li><code>N_split</code> Number of data splits (&gt; 1) to sequentially extract data from, to reduce memory consumption (optional; default: no splitting)</li> <li><code>part_idx</code> Part index (from 0 to N_split-1) to run data extraction only on a specific data split; -1 to merge existing splits and build model (optional; default: data extraction and model building for all splits)</li> </ul>"},{"location":"modelling/#src.connalysis.modelling.modelling.run_model_building--see-also","title":"See Also","text":"<p>run_pathway_model_building : Main model building function for differet source/target node populations conn_prob_2nd_order_model : 2nd-order model building function wrapper for same source/target node population to be used within a processing pipeline conn_prob_3rd_order_model : 3rd-order model building function wrapper for same source/target node population to be used within a processing pipeline</p>"},{"location":"modelling/#src.connalysis.modelling.modelling.run_model_building--references","title":"References","text":"<p>.. [1] Gal E, Perin R, Markram H, London M, Segev I, \"Neuron Geometry Underlies Universal Network Features in Cortical Microcircuits,\" bioRxiv, doi: https://doi.org/10.1101/656058.</p> Source code in <code>src/connalysis/modelling/modelling.py</code> <pre><code>def run_model_building(adj, node_properties, model_name, model_order, **kwargs):\n\"\"\"Main function for probability model building, consisting of three steps: Data extraction, model fitting, and (optionally) data/model visualization.\n\n    Parameters\n    ----------\n    adj : scipy.sparse\n        Sparse (symmetric) adjacency matrix of the circuit\n    node_properties : pandas.DataFrame\n        Data frame with neuron properties\n    model_name : str\n        Name of the model (to be used in file names, ...)\n    model_order : int\n        Model order (2 or 3)\n    kwargs : dict, optional\n        Additional model building settings; see Notes for details\n\n    Returns\n    -------\n    dict\n        Data dictionary containing extracted data points (connection probabilities) from the \"extract\" step; Data/figures also written to output directories as specified in kwargs\n    dict\n        Model dictionary containing probability model fitted to data points from \"model fitting\" step; Model/figures also written to output directories as specified in kwargs\n\n    Raises\n    ------\n    AssertionError\n        If the adjacency matrix is not a square matrix matching the length of the neuron properties table\n    AssertionError\n        If model order not supported (supported: 2, 3)\n    AssertionError\n        If model fitting error occurs\n    KeyError\n        If name(s) of coordinates not in columns of neuron properties table\n\n    Notes\n    -----\n    The adjacency matrix encodes connectivity between source (rows) and taget (columns) neurons.\n\n    The 2nd-order and 3rd-order models as defined in [1]_ are supported. See \"See Also\" for details.\n\n    `kwargs` may contain following (optional) settings:\n\n    - `bin_size_um` Bin size in um for depth binning (optional; default: 100)\n    - `max_range_um` Max. distance range in um to consider (optional; default: full distance range)\n    - `sample_size` Size of random subset of neurons to consider (optional; default: no subsampling)\n    - `sample_seed` Seed for reproducible selection of random subset of neurons (optional)\n    - `coord_names` Names of the coordinates (columns in neuron properties table) based on which to compute Euclidean distance (optional; default: [\"x\", \"y\", \"z\"])\n    - `depth_name` Name of depth coordinate (column in neuron properties table) to use in 3rd-order (bipolar) model (optional; default: \"depth\")\n    - `model_dir` Output directory where to save the model (optional; default: no saving)\n    - `data_dir` Output directory where to save the extracted data (optional; default: no saving)\n    - `do_plot` Enable/disable output plotting (optional; default: no plotting)\n    - `plot_dir` Output directory where to save the plots, if plotting enabled (optional; default: no saving)\n    - `N_split` Number of data splits (&gt; 1) to sequentially extract data from, to reduce memory consumption (optional; default: no splitting)\n    - `part_idx` Part index (from 0 to N_split-1) to run data extraction only on a specific data split; -1 to merge existing splits and build model (optional; default: data extraction and model building for all splits)\n\n    See Also\n    --------\n    run_pathway_model_building : Main model building function for differet source/target node populations\n    conn_prob_2nd_order_model : 2nd-order model building function wrapper for same source/target node population to be used within a processing pipeline\n    conn_prob_3rd_order_model : 3rd-order model building function wrapper for same source/target node population to be used within a processing pipeline\n\n    References\n    ----------\n    .. [1] Gal E, Perin R, Markram H, London M, Segev I, \"Neuron Geometry Underlies Universal Network Features in Cortical Microcircuits,\" bioRxiv, doi: https://doi.org/10.1101/656058.\n\n    \"\"\"\n\n    logging.info(f'Running order-{model_order} model building {kwargs}...')\n\n    assert adj.shape[0] == adj.shape[1] == node_properties.shape[0], 'ERROR: Data size mismatch!'\n\n    # Subsampling (optional)\n    sample_size = kwargs.get('sample_size')\n    sample_seed = kwargs.get('sample_seed')\n    if sample_size is not None and sample_size &gt; 0 and sample_size &lt; node_properties.shape[0]:\n        logging.info(f'Subsampling to {sample_size} of {node_properties.shape[0]} neurons (seed={sample_seed})')\n        np.random.seed(sample_seed)\n        sub_sel = np.random.permutation([True] * sample_size + [False] * (node_properties.shape[0] - sample_size))\n        adj = adj.tocsr()[sub_sel, :].tocsc()[:, sub_sel].tocsr()\n        node_properties = node_properties.loc[sub_sel, :]\n\n    # Set modelling functions\n    if model_order == 2: # Distance-dependent\n        fct_extract = _extract_2nd_order\n        fct_fit = _build_2nd_order\n        fct_plot = _plot_2nd_order\n    elif model_order == 3: # Bipolar distance-dependent\n        fct_extract = _extract_3rd_order\n        fct_fit = _build_3rd_order\n        fct_plot = _plot_3rd_order\n    else:\n        assert False, f'ERROR: Order-{model_order} model building not supported!'\n\n    # Data splits (optional)\n    N_split = kwargs.pop('N_split', None)\n    part_idx = kwargs.pop('part_idx', None)\n    if N_split is None:\n        split_indices = None\n    else:\n        assert N_split &gt; 1, 'ERROR: Number of data splits must be larger than 1!'\n        split_indices = np.split(np.arange(node_properties.shape[0]), np.cumsum([np.ceil(node_properties.shape[0] / N_split).astype(int)] * (N_split - 1)))\n\n    if part_idx is None or part_idx == -1: # Run data extraction and model building for all splits\n        extract_only = False\n        data_fn = 'data'\n    else: # Run only data extraction of given part idx\n        assert N_split is not None and 0 &lt;= part_idx &lt; N_split, 'ERROR: Part index out of range!'\n        extract_only = True\n        data_fn = 'data' + _get_data_part_name(N_split, part_idx)\n\n    # Extract connection probability data\n    if part_idx == -1: # Special case: Load and merge results of existing parts\n        assert N_split is not None, 'ERROR: Number of data splits required!'\n        data_dict = _merge_data(kwargs.get('data_dir'), model_name, data_fn, [_get_data_part_name(N_split, p) for p in range(N_split)])\n    else:\n        data_dict = fct_extract(adj, node_properties, split_indices=split_indices, part_idx=part_idx, **kwargs)\n    _save_data(data_dict, kwargs.get('data_dir'), model_name, data_fn)\n\n    if extract_only: # Stop here and return data dict\n        return data_dict, {}\n\n    # Fit model\n    model_dict = fct_fit(**data_dict, **kwargs)\n    _save_data(model_dict, kwargs.get('model_dir'), model_name, 'model')\n\n    # Visualize data/model (optional)\n    if kwargs.get('do_plot'):\n        fct_plot(adj, node_properties, model_name, **data_dict, **model_dict, **kwargs)\n\n    return data_dict, model_dict\n</code></pre>"},{"location":"modelling/#src.connalysis.modelling.modelling.run_pathway_model_building","title":"<code>run_pathway_model_building(adj, node_properties_src, node_properties_tgt, model_name, model_order, **kwargs)</code>","text":"<p>Main function for probability model building for pathways with different source and target node populations, consisting of three steps: Data extraction, model fitting, and (optionally) data/model visualization.</p> <p>Parameters:</p> Name Type Description Default <code>adj</code> <code>scipy.sparse</code> <p>Sparse adjacency matrix of the circuit (may be non-symmetric)</p> required <code>node_properties_src</code> <code>pandas.DataFrame</code> <p>Data frame with source neuron properties (corresponding to the rows in adj)</p> required <code>node_properties_tgt</code> <code>pandas.DataFrame</code> <p>Data frame with target neuron properties (corresponding to the columns in adj)</p> required <code>model_name</code> <code>str</code> <p>Name of the model (to be used in file names, ...)</p> required <code>model_order</code> <code>int</code> <p>Model order (2 or 3)</p> required <code>kwargs</code> <code>dict</code> <p>Additional model building settings; see \"See Also\" for details</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict</code> <p>Data dictionary containing extracted data points (connection probabilities) from the \"extract\" step; Data/figures also written to output directories as specified in kwargs</p> <code>dict</code> <p>Model dictionary containing probability model fitted to data points from \"model fitting\" step; Model/figures also written to output directories as specified in kwargs</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If the rows/columns of the adjacency matrix are not matching the lengths of the source/target neuron properties tables</p> <code>AssertionError</code> <p>If model order not supported (supported: 2, 3)</p> <code>AssertionError</code> <p>If model fitting error occurs</p> <code>AssertionError</code> <p>If data splitting selected, which is not supported for pathway model building</p> <code>KeyError</code> <p>If name(s) of coordinates not in columns of neuron properties table</p>"},{"location":"modelling/#src.connalysis.modelling.modelling.run_pathway_model_building--notes","title":"Notes","text":"<p>The adjacency matrix encodes connectivity between source (rows) and taget (columns) neurons.</p> <p>The 2nd-order and 3rd-order models as defined in [1]_ are supported. See \"See Also\" for details.</p>"},{"location":"modelling/#src.connalysis.modelling.modelling.run_pathway_model_building--see-also","title":"See Also","text":"<p>run_model_building : Main model building function for same source/target node populations; further details to be found here conn_prob_2nd_order_pathway_model : 2nd-order model building function wrapper for different source/target node populations to be used within a processing pipeline conn_prob_3rd_order_pathway_model : 3rd-order model building function wrapper for different source/target node populations to be used within a processing pipeline</p>"},{"location":"modelling/#src.connalysis.modelling.modelling.run_pathway_model_building--references","title":"References","text":"<p>.. [1] Gal E, Perin R, Markram H, London M, Segev I, \"Neuron Geometry Underlies Universal Network Features in Cortical Microcircuits,\" bioRxiv, doi: https://doi.org/10.1101/656058.</p> Source code in <code>src/connalysis/modelling/modelling.py</code> <pre><code>def run_pathway_model_building(adj, node_properties_src, node_properties_tgt, model_name, model_order, **kwargs):\n\"\"\"Main function for probability model building for pathways with different source and target node populations, consisting of three steps: Data extraction, model fitting, and (optionally) data/model visualization.\n\n    Parameters\n    ----------\n    adj : scipy.sparse\n        Sparse adjacency matrix of the circuit (may be non-symmetric)\n    node_properties_src : pandas.DataFrame\n        Data frame with source neuron properties (corresponding to the rows in adj)\n    node_properties_tgt : pandas.DataFrame\n        Data frame with target neuron properties (corresponding to the columns in adj)\n    model_name : str\n        Name of the model (to be used in file names, ...)\n    model_order : int\n        Model order (2 or 3)\n    kwargs : dict, optional\n        Additional model building settings; see \"See Also\" for details\n\n    Returns\n    -------\n    dict\n        Data dictionary containing extracted data points (connection probabilities) from the \"extract\" step; Data/figures also written to output directories as specified in kwargs\n    dict\n        Model dictionary containing probability model fitted to data points from \"model fitting\" step; Model/figures also written to output directories as specified in kwargs\n\n    Raises\n    ------\n    AssertionError\n        If the rows/columns of the adjacency matrix are not matching the lengths of the source/target neuron properties tables\n    AssertionError\n        If model order not supported (supported: 2, 3)\n    AssertionError\n        If model fitting error occurs\n    AssertionError\n        If data splitting selected, which is not supported for pathway model building\n    KeyError\n        If name(s) of coordinates not in columns of neuron properties table\n\n    Notes\n    -----\n    The adjacency matrix encodes connectivity between source (rows) and taget (columns) neurons.\n\n    The 2nd-order and 3rd-order models as defined in [1]_ are supported. See \"See Also\" for details.\n\n    See Also\n    --------\n    run_model_building : Main model building function for same source/target node populations; further details to be found here\n    conn_prob_2nd_order_pathway_model : 2nd-order model building function wrapper for different source/target node populations to be used within a processing pipeline\n    conn_prob_3rd_order_pathway_model : 3rd-order model building function wrapper for different source/target node populations to be used within a processing pipeline\n\n    References\n    ----------\n    .. [1] Gal E, Perin R, Markram H, London M, Segev I, \"Neuron Geometry Underlies Universal Network Features in Cortical Microcircuits,\" bioRxiv, doi: https://doi.org/10.1101/656058.\n\n    \"\"\"\n\n    logging.info(f'Running order-{model_order} model building {kwargs}...')\n\n    assert adj.shape[0] == node_properties_src.shape[0] and adj.shape[1] == node_properties_tgt.shape[0], 'ERROR: Data size mismatch!'\n\n    # Subsampling (optional)\n    sample_size = kwargs.get('sample_size')\n    sample_seed = kwargs.get('sample_seed')\n    if sample_size is not None and sample_size &gt; 0 and sample_size &lt; np.maximum(node_properties_src.shape[0], node_properties_tgt.shape[0]):\n        logging.info(f'Subsampling to {sample_size} of {node_properties_src.shape[0]}x{node_properties_tgt.shape[0]} neurons (seed={sample_seed})')\n        np.random.seed(sample_seed)\n        if sample_size &lt; node_properties_src.shape[0]:\n            sub_sel_src = np.random.permutation([True] * sample_size + [False] * (node_properties_src.shape[0] - sample_size))\n        else:\n            sub_sel_src = np.full(node_properties_src.shape[0], True)\n\n        if sample_size &lt; node_properties_tgt.shape[0]:\n            sub_sel_tgt = np.random.permutation([True] * sample_size + [False] * (node_properties_tgt.shape[0] - sample_size))\n        else:\n            sub_sel_tgt = np.full(node_properties_tgt.shape[0], True)\n\n        adj = adj.tocsr()[sub_sel_src, :].tocsc()[:, sub_sel_tgt].tocsr()\n        # adj = adj[sub_sel_src, :][:, sub_sel_tgt]\n        node_properties_src = node_properties_src.loc[sub_sel_src, :]\n        node_properties_tgt = node_properties_tgt.loc[sub_sel_tgt, :]\n\n    # Set modelling functions\n    if model_order == 2: # Distance-dependent\n        fct_extract = _extract_2nd_order_pathway\n        fct_fit = _build_2nd_order\n        fct_plot = _plot_2nd_order\n    elif model_order == 3: # Bipolar distance-dependent\n        fct_extract = _extract_3rd_order_pathway\n        fct_fit = _build_3rd_order\n        fct_plot = _plot_3rd_order\n    else:\n        assert False, f'ERROR: Order-{model_order} model building not supported!'\n\n    # Data splits (optional)\n    N_split = kwargs.pop('N_split', None)\n    part_idx = kwargs.pop('part_idx', None)\n    assert N_split is None and part_idx is None, 'ERROR: Data splitting not supported!'\n    data_fn = 'data'\n\n    # Extract connection probability data\n    data_dict = fct_extract(adj, node_properties_src, node_properties_tgt, split_indices=None, part_idx=None, **kwargs)\n    _save_data(data_dict, kwargs.get('data_dir'), model_name, data_fn)\n\n    # Fit model\n    model_dict = fct_fit(**data_dict, **kwargs)\n    _save_data(model_dict, kwargs.get('model_dir'), model_name, 'model')\n\n    # Visualize data/model (optional)\n    if kwargs.get('do_plot'):\n        fct_plot(adj, [node_properties_src, node_properties_tgt], model_name, **data_dict, **model_dict, **kwargs)\n\n    return data_dict, model_dict\n</code></pre>"},{"location":"network/","title":"Functions for working with networks","text":"<p>This page describes functions contained in the <code>network</code> module.  The functions are arranged by motivation, either from classic graph and network theory, or from topology.</p>"},{"location":"network/#topology","title":"Topology","text":"<p>These functions are topologically motivated.</p>"},{"location":"network/#src.connalysis.network.topology.bedge_counts","title":"<code>bedge_counts(adjacency, simplices = None, max_simplices = False, max_dim = -1, simplex_type = 'directed', **kwargs)</code>","text":"<p>Count the sum number of edges per position on the subgraphs defined by the nodes of the simplices in simplices.</p> <p>Parameters:</p> Name Type Description Default <code>adjacency</code> <code>(N,N)-array or sparse matrix</code> <p>Adjacency matrix of a directed network.  A non-zero entry adj[i,j] implies there is an edge from i to j. The matrix can be asymmetric, but must have 0 in the diagonal.</p> required <code>simplices</code> <code>series</code> <p>Series  of 2d-arrays indexed by dimension. Each array is of dimension (no. of simplices, dimension). Each row corresponds to a list of nodes on a simplex.</p> <code>None</code> <code>max_simplices</code> <code>bool</code> <p>If False counts all simplices in adj. If True counts only maximal simplices i.e., simplex motifs that are not contained in higher dimensional ones.</p> <code>False</code> <code>max_dim</code> <code>int</code> <p>Maximal dimension up to which simplex motifs are counted. The default max_dim = -1 counts all existing dimensions.  Particularly useful for large or dense graphs.</p> <code>-1</code> <code>simplex_type</code> <p>See simplex_counts</p> <code>'directed'</code> <p>Returns:</p> Type Description <code>series</code> <p>pandas series with index dimensions values (dim+1, dim+1) arrays.  The (i,j) entry counts the number of edges from node i to node j on all the subgraphs of adjacency on the nodes of the simplices listed.  See notes.</p>"},{"location":"network/#src.connalysis.network.topology.bedge_counts--notes","title":"Notes","text":"<p>Every directed \\(k\\)-simplex \\([v_o, v_1, \\ldots, v_k]\\) defines as subgraph of the adjacency matrix, with edges \\(v_i \\to v_j\\) whenever \\(i\\leq j\\), but also possibly with ''reverse'' edges.  One can represent this structure with a non-symmetric \\((k+1, k+1)\\)-matrix with <code>1</code>'s for every edge in the subgraph.  The output of this function gives for each dimension the sum of all these matrices over all the simplices provided in <code>simplices</code> or over all the simplices in the adjacency matrix if none is provided.  The lower triangular part of these matrices is therefore a metric of recurrence within simplices, or \"higher dimensional recurrence\". In particular, in dimension 1 it is the number of reciprocal edges in the network.</p> Source code in <code>src/connalysis/network/topology.py</code> <pre><code>def bedge_counts(adjacency, simplices=None,\n                 max_simplices = False, max_dim = -1, simplex_type = 'directed', ** kwargs):\n\"\"\"Count the sum number of edges per position on the subgraphs defined by the nodes of the simplices in simplices.\n\n        Parameters\n        ----------\n        adjacency : (N,N)-array or sparse matrix\n            Adjacency matrix of a directed network.  A non-zero entry adj[i,j] implies there is an edge from i to j.\n            The matrix can be asymmetric, but must have 0 in the diagonal.\n        simplices : series\n            Series  of 2d-arrays indexed by dimension.\n            Each array is of dimension (no. of simplices, dimension).\n            Each row corresponds to a list of nodes on a simplex.\n        max_simplices : bool\n            If False counts all simplices in adj.\n            If True counts only maximal simplices i.e., simplex motifs that are not contained in higher dimensional ones.\n        max_dim : int\n            Maximal dimension up to which simplex motifs are counted.\n            The default max_dim = -1 counts all existing dimensions.  Particularly useful for large or dense graphs.\n        simplex_type: str\n            See [simplex_counts](network.md#src.connalysis.network.topology.simplex_counts)\n\n        Returns\n        -------\n        series\n            pandas series with index dimensions values (dim+1, dim+1) arrays.  The (i,j) entry counts the number of edges\n            from node i to node j on all the subgraphs of adjacency on the nodes of the simplices listed.  See notes.\n\n        Notes\n        -------\n        Every directed $k$-simplex $[v_o, v_1, \\\\ldots, v_k]$ defines as subgraph of the adjacency matrix, with edges\n        $v_i \\\\to v_j$ whenever $i\\leq j$, but also possibly with ''reverse'' edges.  One can represent this structure\n        with a non-symmetric $(k+1, k+1)$-matrix with `1`'s for every edge in the subgraph.  The output of this function\n        gives for each dimension the sum of all these matrices over all the simplices provided in `simplices` or over\n        all the simplices in the adjacency matrix if none is provided.  The lower triangular part of these matrices is\n        therefore a metric of recurrence within simplices, or \"higher dimensional recurrence\".\n        In particular, in dimension 1 it is the number of reciprocal edges in the network.\n        \"\"\"\n\n    adj = adjacency\n\n    if simplices is None:\n        LOG.info(\"COMPUTE `bedge_counts(...)`: No argued simplices.\")\n        return bedge_counts(adj,\n                            list_simplices_by_dimension(adj, max_simplices = max_simplices,\n                                                        max_dim = max_dim, simplex_type = simplex_type, ** kwargs))\n    else:\n        LOG.info(\"COMPUTE `bedge_counts(...): for simplices: %s \", simplices.shape)\n\n    dense = np.array(adjacency.toarray(), dtype=int)\n\n    def subset_adj(simplex):\n        return dense[simplex].T[simplex]\n\n    def count_bedges(simplices_given_dim):\n\"\"\"...\"\"\"\n        try:\n            d_simplices = simplices_given_dim.get_value()\n        except AttributeError:\n            d_simplices = simplices_given_dim\n\n        if d_simplices is None or d_simplices.shape[1] == 1:\n            return np.nan\n\n        return (pd.DataFrame(d_simplices, columns=range(d_simplices.shape[1]))\n                .apply(subset_adj, axis=1)\n                .agg(\"sum\"))\n\n    return simplices.apply(count_bedges)\n</code></pre>"},{"location":"network/#src.connalysis.network.topology.betti_counts","title":"<code>betti_counts(adj, node_properties = None, min_dim = 0, max_dim = [], simplex_type = 'directed', approximation = None, **kwargs)</code>","text":"<p>Count betti counts of flag complex of adj.  Type of flag complex is given by simplex_type.</p> <p>Parameters:</p> Name Type Description Default <code>adj</code> <code>2d (N,N)-array or sparse matrix</code> <p>Adjacency matrix of a directed network.  A non-zero entry adj[i,j] implies there is an edge from i to j. The matrix can be asymmetric, but must have 0 in the diagonal.  Matrix will be cast to 0,1 entries so weights will be ignored.</p> required <code>node_properties</code> <code> data frame</code> <p>Data frame of neuron properties in adj.  Only necessary if used in conjunction with TAP or connectome utilities.</p> <code>None</code> <code>min_dim</code> <code>int</code> <p>Minimal dimension from which betti counts are computed. The default min_dim = 0 (counting number of connected components).</p> <code>0</code> <code>max_dim</code> <code>int</code> <p>Maximal dimension up to which simplex motifs are counted. The default max_dim = [] counts betti numbers up to the maximal dimension of the complex.</p> <code>[]</code> <code>simplex_type</code> <code>string</code> <p>Type of flag complex to consider, given by the type of simplices it is built on. Possible types are:</p> <p>\u2019directed\u2019 - directed simplices (directed flag complex)</p> <p>\u2019undirected\u2019 - simplices in the underlying undirected graph (clique complex of the underlying undirected graph)</p> <p>\u2019reciprocal\u2019 - simplices in the undirected graph of reciprocal connections (clique complex of the undirected graph of reciprocal connections.)</p> <code>'directed'</code> <code>approximation</code> <code>list of integers  or None</code> <p>Approximation parameter for the computation of the betti numbers.  Useful for large networks. If None all betti numbers are computed exactly. Otherwise, min_dim must be 0 and approximation but be a list of positive integers or -1. The list approximation is either extended by -1 entries on the right or sliced from [0:max_dim+1] to obtain a list of length max_dim.  Each entry of the list denotes the approximation value for the betti computation of that dimension if -1 approximation in that dimension is set to None.</p> <p>If the approximation value at a given dimension is <code>a</code> flagser skips cells creating columns in the reduction matrix with more than <code>a</code> entries.  This is useful for hard problems.  For large, sparse networks a good value if often <code>100,00</code>.  If set to <code>1</code> that dimension will be virtually ignored.  See [1]_</p> <code>None</code> <p>Returns:</p> Type Description <code>series</code> <p>Betti counts indexed per dimension from min_dim to max_dim.</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If adj has non-zero entries in the diagonal which can produce errors.</p> <code>AssertionError</code> <p>If adj is not square.</p> <code>AssertionError</code> <p>If approximation != None and min_dim != 0.</p>"},{"location":"network/#src.connalysis.network.topology.betti_counts--see-also","title":"See Also","text":"<p>simplex_counts : A function that counts the simplices forming the complex from which bettis are count. Simplex types are described there in detail.</p>"},{"location":"network/#src.connalysis.network.topology.betti_counts--references","title":"References","text":"<p>For details about the approximation algorithm see</p> <p>..[1] D. Luetgehetmann, \"Documentation of the C++ flagser library\";        GitHub: luetge/flagser.</p> Source code in <code>src/connalysis/network/topology.py</code> <pre><code>def betti_counts(adj, node_properties=None,\n                 min_dim=0, max_dim=[], simplex_type='directed', approximation=None,\n                 **kwargs):\n\"\"\"Count betti counts of flag complex of adj.  Type of flag complex is given by simplex_type.\n\n    Parameters\n    ----------\n    adj : 2d (N,N)-array or sparse matrix\n        Adjacency matrix of a directed network.  A non-zero entry adj[i,j] implies there is an edge from i to j.\n        The matrix can be asymmetric, but must have 0 in the diagonal.  Matrix will be cast to 0,1 entries so weights\n        will be ignored.\n    node_properties :  data frame\n        Data frame of neuron properties in adj.  Only necessary if used in conjunction with TAP or connectome utilities.\n    min_dim : int\n        Minimal dimension from which betti counts are computed.\n        The default min_dim = 0 (counting number of connected components).\n    max_dim : int\n        Maximal dimension up to which simplex motifs are counted.\n        The default max_dim = [] counts betti numbers up to the maximal dimension of the complex.\n    simplex_type : string\n        Type of flag complex to consider, given by the type of simplices it is built on.\n        Possible types are:\n\n        \u2019directed\u2019 - directed simplices (directed flag complex)\n\n        \u2019undirected\u2019 - simplices in the underlying undirected graph (clique complex of the underlying undirected graph)\n\n        \u2019reciprocal\u2019 - simplices in the undirected graph of reciprocal connections (clique complex of the\n        undirected graph of reciprocal connections.)\n    approximation : list of integers  or None\n        Approximation parameter for the computation of the betti numbers.  Useful for large networks.\n        If None all betti numbers are computed exactly.\n        Otherwise, min_dim must be 0 and approximation but be a list of positive integers or -1.\n        The list approximation is either extended by -1 entries on the right or sliced from [0:max_dim+1] to obtain\n        a list of length max_dim.  Each entry of the list denotes the approximation value for the betti computation\n        of that dimension if -1 approximation in that dimension is set to None.\n\n        If the approximation value at a given dimension is `a` flagser skips cells creating columns in the reduction\n        matrix with more than `a` entries.  This is useful for hard problems.  For large, sparse networks a good value\n        if often `100,00`.  If set to `1` that dimension will be virtually ignored.  See [1]_\n\n    Returns\n    -------\n    series\n        Betti counts indexed per dimension from min_dim to max_dim.\n\n    Raises\n    ------\n    AssertionError\n        If adj has non-zero entries in the diagonal which can produce errors.\n    AssertionError\n        If adj is not square.\n    AssertionError\n        If approximation != None and min_dim != 0.\n\n    See Also\n    --------\n    [simplex_counts](network.md#src.connalysis.network.topology.simplex_counts) :\n    A function that counts the simplices forming the complex from which bettis are count.\n    Simplex types are described there in detail.\n\n    References\n    ----------\n    For details about the approximation algorithm see\n\n    ..[1] D. Luetgehetmann, \"Documentation of the C++ flagser library\";\n           [GitHub: luetge/flagser](https://github.com/luetge/flagser/blob/master/docs/documentation_flagser.pdf).\n\n    \"\"\"\n    LOG.info(\"Compute betti counts for %s-type adjacency matrix and %s-type node properties\",\n             type(adj), type(node_properties))\n\n    from pyflagser import flagser_unweighted\n\n    #Checking matrix\n    adj = sp.csr_matrix(adj).astype(bool).astype('int')\n    assert np.count_nonzero(adj.diagonal()) == 0, 'The diagonal of the matrix is non-zero and this may lead to errors!'\n    N, M = adj.shape\n    assert N == M, 'Dimension mismatch. The matrix must be square.'\n    assert not((not approximation is None) and (min_dim!=0)), \\\n        'For approximation != None, min_dim must be set to 0.  \\nLower dimensions can be ignored by setting approximation to 1 on those dimensions'\n\n    # Symmetrize matrix if simplex_type is not 'directed'\n    if simplex_type == 'undirected':\n        adj = sp.triu(underlying_undirected_matrix(adj))  # symmtrize and keep upper triangular only\n    elif simplex_type == \"reciprocal\":\n        adj = sp.triu(rc_submatrix(adj))  # symmtrize and keep upper triangular only\n    #Computing bettis\n    if max_dim==[]:\n        max_dim=np.inf\n\n    if approximation==None:\n        LOG.info(\"Run without approximation\")\n        bettis = flagser_unweighted(adj, min_dimension=min_dim, max_dimension=max_dim,\n                                    directed=True, coeff=2,\n                                    approximation=None)['betti']\n    else:\n        assert (all([isinstance(item,int) for item in approximation])) # assert it's a list of integers\n        approximation=np.array(approximation)\n        bettis=[]\n\n        #Make approximation vector to be of size max_dim\n        if max_dim!=np.inf:\n            if approximation.size-1 &lt; max_dim:#Vector too short so pad with -1's\n                approximation=np.pad(approximation,\n                                     (0,max_dim-(approximation.size-1)),\n                                     'constant',constant_values=-1)\n            if approximation.size-1&gt;max_dim:#Vector too long, select relevant slice\n                approximation=approximation[0:max_dim+1]\n            #Sanity check\n            LOG.info(\"Correct dimensions for approximation: %s\", approximation.size==max_dim+1)\n\n        #Split approximation into sub-vectors of same value to speed up computation\n        diff=approximation[1:]-approximation[:-1]\n        slice_indx=np.array(np.where(diff!=0)[0])+1\n\n        #Compute betti counts\n        for dims_range in  np.split(np.arange(approximation.size),slice_indx):\n            n=dims_range[0] #min dim for computation\n            N=dims_range[-1] #max dim for computation\n            a=approximation[n]\n            if a==-1:\n                a=None\n            LOG.info(\"Run betti for dim range %s-%s with approximation %s\", n,N,a)\n            bettis=bettis+flagser_unweighted(adj, min_dimension=n, max_dimension=N,\n                                             directed=True, coeff=2,\n                                             approximation=a)['betti']\n\n        if max_dim==np.inf:\n            n=approximation.size #min dim for computation\n            N=np.inf #max dim for computation\n            a=None\n            LOG.info(\"Run betti for dim range %s-%s with approximation %s\",n,N,a)\n            bettis=bettis+flagser_unweighted(adj, min_dimension=n, max_dimension=N,\n                                             directed=True, coeff=2,\n                                             approximation=a)['betti']\n\n    return pd.Series(bettis, name=\"betti_count\",\n                     index=pd.Index(np.arange(min_dim, len(bettis)+min_dim), name=\"dim\"))\n</code></pre>"},{"location":"network/#src.connalysis.network.topology.count_rc_edges_k_skeleton","title":"<code>count_rc_edges_k_skeleton(simplex_list_at_dim, N, position = 'all', return_mat = False)</code>","text":"<p>Count the edges and reciprocal edges in the simplex list provided. If the list is all the k (maximal)simplices of a directed flag complex, it is counting the number of edges and reciprocal edges of the its k-skeleton.</p> <p>Parameters:</p> Name Type Description Default <code>simplex_list_at_dim</code> <p>Array of dimension (no. of simplices, dimension). Each row corresponds to a list of nodes on a simplex indexed by the ordering given for all nodes in the graph</p> required <code>N</code> <p>Number of nodes in original graph</p> required <code>position</code> <p>Position of the edges to extract</p> <p>'all': all edges of the simplex</p> <p>'spine': edges along the spine of the simplex (only makes sense for directed simplices)</p> <code>'all'</code> <p>Returns:</p> Type Description <code>tuple of ints</code> <p>Counts of (edges, reciprocal edges) in the simplex list</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If N &lt;= than an entry in the simplex list</p> Source code in <code>src/connalysis/network/topology.py</code> <pre><code>def count_rc_edges_k_skeleton(simplex_list_at_dim, N, position=\"all\", return_mat=False):\n\"\"\"Count the edges and reciprocal edges in the simplex list provided.\n    If the list is all the k (maximal)simplices of a directed flag complex, it is counting the number of\n    edges and reciprocal edges of the its k-skeleton.\n\n    Parameters\n    ----------\n    simplex_list_at_dim: 2d-array\n        Array of dimension (no. of simplices, dimension).\n        Each row corresponds to a list of nodes on a simplex indexed by the\n        ordering given for all nodes in the graph\n    N: int\n        Number of nodes in original graph\n    position: str\n        Position of the edges to extract\n\n        'all': all edges of the simplex\n\n        'spine': edges along the spine of the simplex\n        (only makes sense for directed simplices)\n\n    Returns\n    -------\n    tuple of ints\n        Counts of (edges, reciprocal edges) in the simplex list\n\n    Raises\n    ------\n    AssertionError\n        If N &lt;= than an entry in the simplex list\n    \"\"\"\n\n    assert N &gt; np.max(simplex_list_at_dim), \\\n        \"N must be larger than all the entries in the simplex list\"\n\n    mat = extract_submatrix_of_simplices(simplex_list_at_dim, N, position=position)\n    edge_counts = mat.sum()\n    rc_edge_counts = rc_submatrix(mat).sum()\n    # Return mats?\n    if return_mat == True:\n        return edge_counts, rc_edge_counts, mat\n    else:\n        return edge_counts, rc_edge_counts\n</code></pre>"},{"location":"network/#src.connalysis.network.topology.count_rc_edges_skeleta","title":"<code>count_rc_edges_skeleta(adj = None, max_dim = -1, max_simplices = False, simplex_list = None, N = None, position = 'all', return_mats = False, **kwargs)</code>","text":"<p>Count the edges and reciprocal edges in the k-skeleta of the directed flag complex of adj for all k&lt;= max_dim. If simplex list are provided, it will compute the skeleta directly from these and not use adj.</p> <p>Parameters:</p> Name Type Description Default <code>adj</code> <code>(N,N)-array or sparse matrix</code> <p>Adjacency matrix of a directed network.  A non-zero entry adj[i,j] implies there is an edge from i to j. The matrix can be asymmetric, but must have 0 in the diagonal.</p> <code>None</code> <code>max_simplices</code> <code>bool</code> <p>If False counts all simplices in adj. If True counts only maximal simplices i.e., simplex motifs that are not contained in higher dimensional ones.</p> <code>False</code> <code>max_dim</code> <code>int</code> <p>Maximal dimension up to which simplex motifs are counted. The default max_dim = -1 counts all existing dimensions.  Particularly useful for large or dense graphs.</p> <code>-1</code> <code>simplex</code> <p>Series 2d-arrays indexed by dimension. Each array is of dimension (no. of simplices, dimension). Each row corresponds to a list of nodes on a simplex. If provided adj will be ignored but N will be required.</p> required <code>N</code> <p>Number of nodes in original graph.</p> <code>None</code> <code>position</code> <p>Position of the edges to extract</p> <p>'all': all edges of the simplex</p> <p>'spine': edges along the spine of the simplex (only makes sense if simplices are directed)</p> <code>'all'</code> <code>return_mats</code> <code>bool</code> <p>If True return the matrices of the underlying graphs of the k-skeleta as in get_k_skeleta_graph.</p> <code>False</code> <p>Returns:</p> Type Description <code>data frame, (dict)</code> <p>data frame with index dimensions and columns number of (rc) edges in the corresponding skeleta if return_mats==True, also return the graphs of the k-skeleta as in get_k_skeleta_graph.</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If neither adj nor simplex_list are provided</p> <code>AssertionError</code> <p>If N &lt;= than an entry in the simplex list</p> Source code in <code>src/connalysis/network/topology.py</code> <pre><code>def count_rc_edges_skeleta(adj=None, max_dim=-1, max_simplices=False,\n                           simplex_list=None, N=None,\n                           position=\"all\", return_mats=False, **kwargs):\n    # check max dim is consistent with simplex_list only used if adj is given and must be &gt;0\n\"\"\"Count the edges and reciprocal edges in the k-skeleta of the directed flag complex of adj for all\n    k&lt;= max_dim. If simplex list are provided, it will compute the skeleta directly from these and not use adj.\n\n    Parameters\n    ----------\n    adj : (N,N)-array or sparse matrix\n        Adjacency matrix of a directed network.  A non-zero entry adj[i,j] implies there is an edge from i to j.\n        The matrix can be asymmetric, but must have 0 in the diagonal.\n    max_simplices : bool\n        If False counts all simplices in adj.\n        If True counts only maximal simplices i.e., simplex motifs that are not contained in higher dimensional ones.\n    max_dim : int\n        Maximal dimension up to which simplex motifs are counted.\n        The default max_dim = -1 counts all existing dimensions.  Particularly useful for large or dense graphs.\n    simplex list: series\n        Series 2d-arrays indexed by dimension.\n        Each array is of dimension (no. of simplices, dimension).\n        Each row corresponds to a list of nodes on a simplex.\n        If provided adj will be ignored but N will be required.\n    N: int\n        Number of nodes in original graph.\n    position: str\n        Position of the edges to extract\n\n        'all': all edges of the simplex\n\n        'spine': edges along the spine of the simplex\n        (only makes sense if simplices are directed)\n    return_mats : bool\n        If True return the matrices of the underlying graphs of the k-skeleta as in\n        get_k_skeleta_graph.\n\n    Returns\n    -------\n    data frame, (dict)\n        data frame with index dimensions and columns number of (rc) edges in the corresponding skeleta\n        if return_mats==True, also return the graphs of the k-skeleta as in get_k_skeleta_graph.\n\n    Raises\n    ------\n    AssertionError\n        If neither adj nor simplex_list are provided\n    AssertionError\n        If N &lt;= than an entry in the simplex list\n    \"\"\"\n\n    assert not (adj is None and simplex_list is None), \"Either adj or simplex_list need to be provided\"\n\n    if (simplex_list is None):  # Compute simplex lists if not provided\n        simplex_list = list_simplices_by_dimension(adj, node_properties=None,\n                                                            max_simplices=max_simplices, max_dim=max_dim,\n                                                            simplex_type='directed',\n                                                            nodes=None, verbose=False, **kwargs)\n        N = adj.shape[0]\n    else:\n        assert N &gt; np.nanmax(simplex_list.explode().explode()), \\\n            \"N must be larger than all the entries in the simplex list\"\n\n    # Extract 'k'-skeleton and count (rc-)edges\n    dims = simplex_list.index[simplex_list.index != 0]  # Doesn't make sense to look at the 0-skeleton\n    edge_counts = pd.DataFrame(index=dims, columns=[\"number_of_edges\", \"number_of_rc_edges\", \"rc/edges_percent\"])\n    if return_mats == True:\n        skeleton_mats = {f'dimension_{dim}': None for dim in dims}\n    print(dims)\n    for dim in dims:\n        if simplex_list[dim].size &gt; 0:\n            edges, rc_edges, mat = count_rc_edges_k_skeleton(simplex_list[dim], N,\n                                                                      position=position, return_mat=True)\n            edge_counts[\"number_of_edges\"].loc[dim] = edges\n            edge_counts[\"number_of_rc_edges\"].loc[dim] = rc_edges\n            edge_counts[\"rc/edges_percent\"].loc[dim] = (rc_edges * 100) / edges\n        else:\n            edge_counts[\"number_of_edges\"].loc[dim] = 0\n        if return_mats == True:\n            skeleton_mats[f'dimension_{dim}'] = mat\n    if return_mats == True:\n        return edge_counts, skeleton_mats\n    else:\n        return edge_counts\n</code></pre>"},{"location":"network/#src.connalysis.network.topology.count_triads_fully_connected","title":"<code>count_triads_fully_connected(adj, max_num_sampled = 5000000, return_normalized = False)</code>","text":"<p>Counts the numbers of each triadic motif in the matrix adj.</p> <p>Parameters:</p> Name Type Description Default <code>adj</code> <code>2d-array</code> <p>Adjacency matrix of a directed network.</p> required <code>max_num_sampled</code> <code>int</code> <p>The maximal number of connected triads classified. If the number of connected triads is higher than that, only the specified number is sampled at random and classified. The final counts are extrapolated as (actual_num_triads/ max_num_sampled) * counts.</p> <code>5000000</code> <code>return_normalized</code> <code>bool</code> <p>If True return the triad counts divided by the size of each isomorphism class.  That is, the total counts divided by the following array:</p> <p>\\([6, 3, 3, 6, 6, 6, 2, 3, 6, 3, 3, 6, 1].\\)</p> <code>False</code> <p>Returns:</p> Type Description <code>1d-array</code> <p>The counts of the various triadic motifs in adj as ordered in Figure 5 [1]_.</p>"},{"location":"network/#src.connalysis.network.topology.count_triads_fully_connected--notes","title":"Notes","text":"<p>Only connectected motifs are counted, i.e. motifs with less than 2 connections or only a single bidirectional connection are not counted. The connected motifs are ordered as in Figure 5 [1]_.</p>"},{"location":"network/#src.connalysis.network.topology.count_triads_fully_connected--references","title":"References","text":"<p>..[1] Gal, Eyal, et al. \"Rich cell-type-specific network topology in neocortical microcircuitry.\" Nature neuroscience 20.7 (2017): 1004-1013.</p> Source code in <code>src/connalysis/network/topology.py</code> <pre><code>def count_triads_fully_connected(adj, max_num_sampled=5000000, return_normalized=False):\n\"\"\"Counts the numbers of each triadic motif in the matrix adj.\n\n    Parameters\n    ----------\n    adj : 2d-array\n        Adjacency matrix of a directed network.\n    max_num_sampled : int\n        The maximal number of connected triads classified. If the number of\n        connected triads is higher than that, only the specified number is sampled at random and\n        classified. The final counts are extrapolated as (actual_num_triads/ max_num_sampled) * counts.\n    return_normalized : bool\n        If True return the triad counts divided by the size of each isomorphism class.  That is, the total counts\n        divided by the following array:\n\n        $[6, 3, 3, 6, 6, 6, 2, 3, 6, 3, 3, 6, 1].$\n\n    Returns\n    -------\n    1d-array\n        The counts of the various triadic motifs in adj as ordered in Figure 5 [1]_.\n\n    Notes\n    ------\n    Only connectected motifs are counted, i.e. motifs with less than 2 connections or only a single bidirectional\n    connection are not counted. The connected motifs are ordered as in Figure 5 [1]_.\n\n    References\n    -------\n\n    ..[1] Gal, Eyal, et al.\n    [\"Rich cell-type-specific network topology in neocortical microcircuitry.\"](https://www.nature.com/articles/nn.4576)\n    Nature neuroscience 20.7 (2017): 1004-1013.\n\n    \"\"\"\n\n    # Functions to indetify triads\n    def canonical_sort(M):\n\"\"\"Sorts row/columns of the matrix adj using the lexicographical order of the\n        tuple (out_degree, in_degree).\n\n        Parameters\n        ----------\n        M : 2d-array\n            Adjacency matrix of a directed network.\n\n        Returns\n        -------\n        2d-array\n            the matrix adj with rows/columns sorted\n        \"\"\"\n        in_degree = np.sum(M, axis=0)\n        out_degree = np.sum(M, axis=1)\n        idx = np.argsort(-in_degree - 10 * out_degree)\n        return M[:, idx][idx]\n\n    def identify_motif(M):\n\"\"\"\n        Identifies the connected directed digraph on three nodes M as on in the full classification\n        list given in the dictionary triad_dict.\n\n        Parameters\n        ----------\n        M : array\n            A (3,3) array describing a directed connected digraph on three nodes.\n\n        Returns\n        -------\n        The index of the motif as indexed in the dictiroanry triad_dict which follows the\n        ordering of Gal et al., 2017\n        \"\"\"\n        triad_code = tuple(np.nonzero(canonical_sort(M).flatten())[0])\n        return triad_dict[triad_code]\n\n    # Finding and counting triads\n    import time\n    adj = adj.toarray()  # Casting to array makes finding triads an order of magnitude faster\n    t0 = time.time()\n    undirected_adj = underlying_undirected_matrix(adj).toarray()\n    # Matrix with i,j entries number of undirected paths between i and j in adj\n    path_counts = np.triu(undirected_adj @ undirected_adj, 1)\n    connected_pairs = np.nonzero(path_counts)\n    triads = set()\n    print(\"Testing {0} potential triadic pairs\".format(len(connected_pairs[0])))\n    for x, y in zip(*connected_pairs):\n        # zs = np.nonzero((undirected_adj.getrow(x).multiply(undirected_adj.getrow(y))).toarray()[0])[0]\n        zs = np.nonzero(undirected_adj[x] &amp; undirected_adj[y])[0]\n        for z in zs:\n            triads.add(tuple(sorted([x, y, z])))\n    triads = list(triads)\n    print(\"Time spent finding triads: {0}\".format(time.time() - t0))\n    print(\"Found {0} connected triads\".format(len(triads)))\n    t0 = time.time()\n    counts = np.zeros(np.max(list(triad_dict.values())) + 1)\n    sample_idx = np.random.choice(len(triads),\n                                  np.minimum(max_num_sampled, len(triads)),\n                                  replace=False)\n    for idx in sample_idx:\n        triad = triads[idx]\n        motif_id = identify_motif(adj[:, triad][triad, :])\n        counts[motif_id] += 1\n    print(\"Time spent classifying triads: {0}\".format(time.time() - t0))\n    if return_normalized:\n        return (((len(triads) / len(sample_idx)) * counts).astype(int)) / triad_combinations\n    else:\n        return (((len(triads) / len(sample_idx)) * counts).astype(int))\n</code></pre>"},{"location":"network/#src.connalysis.network.topology.cross_col_k_in_degree","title":"<code>cross_col_k_in_degree(adj_cross, adj_source, max_simplices = False, threads = 1, max_dim = -1, **kwargs)</code>","text":"<p>Compute generalized in-degree of nodes in adj_target from nodes in adj_source. The k-in-degree of a node v is the number of k-simplices in adj_source with all its nodes mapping to v through edges in adj_cross.</p> <p>Parameters:</p> Name Type Description Default <code>adj_cross</code> <code>(n,m) array or sparse matrix</code> <p>Matrix of connections from the nodes in adj_n to the target population. n is the number of nodes in adj_source and m is the number of nodes in adj_target. A non-zero entry adj_cross[i,j] implies there is an edge from i-th node of adj_source to the j-th node of adj_target.</p> required <code>adj_source</code> <code>(n, n)-array or sparse matrix</code> <p>Adjacency matrix of the source network where n is the number of nodes in the source network. A non-zero entry adj_source[i,j] implies there is an edge from node i to j. The matrix can be asymmetric, but must have 0 in the diagonal.</p> required <code>max_simplices</code> <code>bool</code> <p>If False counts all simplices. If True counts only maximal simplices.</p> <code>False</code> <code>max_dim</code> <code>int</code> <p>Maximal dimension up to which simplex motifs are counted. The default max_dim = -1 counts all existing dimensions. Particularly useful for large or dense graphs.</p> <code>-1</code> <p>Returns:</p> Type Description <code>Data frame</code> <p>Table of cross-k-in-degrees indexed by the m nodes in the target population.</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If adj_source has non-zero entries in the diagonal which can produce errors.</p> Source code in <code>src/connalysis/network/topology.py</code> <pre><code>def cross_col_k_in_degree(adj_cross, adj_source, max_simplices=False,\n                          threads=1,max_dim=-1,**kwargs):\n    #TODO: DO THE OUTDEGREE VERSION\n    #TODO: Get participation directly from flagsercount via vertices to do?\n\"\"\"Compute generalized in-degree of nodes in adj_target from nodes in adj_source.\n    The k-in-degree of a node v is the number of k-simplices in adj_source with all its nodes mapping to v\n    through edges in adj_cross.\n    Parameters\n    ----------\n    adj_cross : (n,m) array or sparse matrix\n        Matrix of connections from the nodes in adj_n to the target population.\n        n is the number of nodes in adj_source and m is the number of nodes in adj_target.\n        A non-zero entry adj_cross[i,j] implies there is an edge from i-th node of adj_source\n        to the j-th node of adj_target.\n    adj_source : (n, n)-array or sparse matrix\n        Adjacency matrix of the source network where n is the number of nodes in the source network.\n        A non-zero entry adj_source[i,j] implies there is an edge from node i to j.\n        The matrix can be asymmetric, but must have 0 in the diagonal.\n    max_simplices : bool\n        If False counts all simplices.\n        If True counts only maximal simplices.\n    max_dim : int\n        Maximal dimension up to which simplex motifs are counted.\n        The default max_dim = -1 counts all existing dimensions.\n        Particularly useful for large or dense graphs.\n\n    Returns\n    -------\n    Data frame\n        Table of cross-k-in-degrees indexed by the m nodes in the target population.\n\n    Raises\n    ------\n    AssertionError\n        If adj_source has non-zero entries in the diagonal which can produce errors.\n    \"\"\"\n    adj_source=sp.csr_matrix(adj_source).astype('bool')\n    adj_cross=sp.csr_matrix(adj_cross).astype('bool')\n    assert np.count_nonzero(adj_source.diagonal()) == 0, \\\n    'The diagonal of the source matrix is non-zero and this may lead to errors!'\n    assert adj_source.shape[0] == adj_source.shape[1], \\\n    'Dimension mismatch. The source matrix must be square.'\n    assert adj_source.shape[0] == adj_cross.shape[0], \\\n    'Dimension mismatch. The source matrix and cross matrix must have the same number of rows.'\n\n    n_source = adj_source.shape[0] #Size of the source population\n    n_target = adj_cross.shape[1] #Size of the target population\n    # Building a square matrix [[adj_source, adj_cross], [0,0]]\n    adj=sp.bmat([[adj_source, adj_cross],\n                 [sp.csr_matrix((n_target, n_source), dtype='bool'),\n                  sp.csr_matrix((n_target, n_target), dtype='bool')]])\n    # Transposing to restrict computation to ``source nodes'' in adj_target in flagsercount\n    adj=adj.T\n    nodes=np.arange(n_source, n_source+n_target) #nodes on target population\n    slist=list_simplices_by_dimension(adj, max_simplices=max_simplices, max_dim=max_dim,nodes=nodes,\n                                      simplex_type='directed',verbose=False,threads=threads,**kwargs)\n\n    #Count participation as a source in transposed matrix i.e. participation as sink in the original\n    cross_col_deg=pd.DataFrame(columns=slist.index[1:], index=nodes)\n    for dim in slist.index[1:]:\n        index,deg=np.unique(slist[dim][:,0],return_counts=True)\n        cross_col_deg[dim].loc[index]=deg\n    cross_col_deg=cross_col_deg.fillna(0)\n    return cross_col_deg\n</code></pre>"},{"location":"network/#src.connalysis.network.topology.extract_submatrix_of_simplices","title":"<code>extract_submatrix_of_simplices(simplex_list, N, position = 'all')</code>","text":"<p>Generate binary submatrix of NxN matrix of edges in simplex list.</p> <p>Parameters:</p> Name Type Description Default <code>simplex</code> <p>Array of dimension (no. of simplices, dimension). Each row corresponds to a list of nodes on a simplex indexed by the order of the nodes in an NxN matrix.</p> required <code>N</code> <p>Number of nodes in original graph defining the NxN matrix.</p> required <code>position</code> <p>Position of the edges to extract</p> <p>'all': all edges of the simplex</p> <p>'spine': edges along the spine of the simplex (only makes sense for directed simplices)</p> <code>'all'</code> <p>Returns:</p> Type Description <code>csr bool matrix</code> <p>Matrix with of shape (N,N) with entries <code>True</code> corresponding to edges in simplices.</p> Source code in <code>src/connalysis/network/topology.py</code> <pre><code>def extract_submatrix_of_simplices(simplex_list, N, position=\"all\"):\n\"\"\"Generate binary submatrix of NxN matrix of edges in simplex list.\n\n    Parameters\n    ----------\n    simplex list: 2d-array\n        Array of dimension (no. of simplices, dimension).\n        Each row corresponds to a list of nodes on a simplex\n        indexed by the order of the nodes in an NxN matrix.\n    N: int\n        Number of nodes in original graph defining the NxN matrix.\n    position: str\n        Position of the edges to extract\n\n        'all': all edges of the simplex\n\n        'spine': edges along the spine of the simplex\n        (only makes sense for directed simplices)\n\n    Returns\n    -------\n    csr bool matrix\n        Matrix with of shape (N,N) with entries `True` corresponding to edges in simplices.\n    \"\"\"\n    if simplex_list.shape[0] == 0:\n        return sp.csr_matrix((N, N), dtype=bool)  # no simplices in this dimension\n    else:\n        dim = simplex_list.shape[1] - 1\n        edges_abstract = _generate_abstract_edges_in_simplices(dim,\n                                                               position=position)  # abstract list of edges to extract from each simplex\n        edges = np.unique(np.concatenate([simplex_list[:, edge] for edge in edges_abstract]), axis=0)\n        return (sp.coo_matrix((np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])), shape=(N, N))).tocsr().astype(bool)\n</code></pre>"},{"location":"network/#src.connalysis.network.topology.get_all_simplices_from_max","title":"<code>get_all_simplices_from_max(max_simplices)</code>","text":"<p>Takes the list of maximal simplices are returns the list of all simplices.</p> <p>Parameters:</p> Name Type Description Default <code>max_simplices</code> <code>list</code> <p>A list of lists of tuples. Where max_simplices[k] is a list of the 0 dimensional maximal simplices, where each simplex is a tuple of the vertices of the simplex</p> required <p>Returns:</p> Type Description <code>list</code> <p>A list of lists of tuples. Of the same format as the inputted list but now contains all simplices.</p> Source code in <code>src/connalysis/network/topology.py</code> <pre><code>def get_all_simplices_from_max(max_simplices):\n\"\"\"Takes the list of maximal simplices are returns the list of all simplices.\n\n        Parameters\n        ----------\n        max_simplices : list\n            A list of lists of tuples. Where max_simplices[k] is a list of the 0 dimensional maximal simplices,\n            where each simplex is a tuple of the vertices of the simplex\n\n        Returns\n        -------\n        list\n            A list of lists of tuples. Of the same format as the inputted list but now contains all simplices.\n        \"\"\"\n    simplices = list(max_simplices)\n    for k in range(len(max_simplices)-1,0,-1):\n        print(max_simplices[k])\n        for simplex in simplices[k]:\n            for s in range(k,-1,-1):\n                x = tuple(simplex[:s]+simplex[s+1:])\n                if x not in simplices[k-1]:\n                    simplices[k-1].append(x)\n\n    return simplices\n</code></pre>"},{"location":"network/#src.connalysis.network.topology.get_k_skeleta_graph","title":"<code>get_k_skeleta_graph(adj = None, max_simplices = False, dimensions = None, simplex_type = 'directed', simplex_list = None, N = None, position = 'all', **kwargs)</code>","text":"<p>Return the edges of the (maximal) k-skeleton of the flag complex of adj for all k&lt;= max_dim in the position determined by position. If simplex list are provided, it will compute the edges directly from these and not use adj, in which case N (the number of rows and columns of adj) is required. If simplex lists are not provided they will be calculated with for the flag complex whose type is determined by simplex_type as for simplex_counts.</p> <p>Parameters:</p> Name Type Description Default <code>adj</code> <code>(N,N)-array or sparse matrix</code> <p>Adjacency matrix of a directed network.  A non-zero entry adj[i,j] implies there is an edge from i to j. The matrix can be asymmetric, but must have 0 in the diagonal.</p> <code>None</code> <code>max_simplices</code> <code>bool</code> <p>If False counts all simplices in adj. If True counts only maximal simplices i.e., simplex motifs that are not contained in higher dimensional ones.</p> <code>False</code> <code>dimensions</code> <code>list of ints</code> <p>Dimensions <code>k</code> for which the <code>k</code>-skeleta is computed, if None all dimensions are computed.</p> <code>None</code> <code>simplex_type</code> <code>string</code> <p>Type of simplex to consider if computed from adj:</p> <p>\u2019directed\u2019 - directed simplices</p> <p>\u2019undirected\u2019 - simplices in the underlying undirected graph</p> <p>\u2019reciprocal\u2019 - simplices in the undirected graph of reciprocal connections</p> <code>'directed'</code> <code>simplex</code> <p>Series 2d-arrays indexed by dimension. Each array is of dimension (no. of simplices, dimension). Each row corresponds to a list of nodes on a simplex. If provided adj will be ignored but N will be required.</p> required <code>N</code> <p>Number of nodes in original graph.</p> <code>None</code> <code>position</code> <p>Position of the edges to extract</p> <p>'all': all edges of the simplex</p> <p>'spine': edges along the spine of the simplex (only makes sense if simplices are directed)</p> <code>'all'</code> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary with keys dimensions and values boolean (N,N) matrices with entries <code>True</code> corresponding to edges in (maximal) simplices of that dimension.</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If neither adj nor simplex_list are provided</p> <code>AssertionError</code> <p>If N &lt;= than an entry in the simplex list</p> <code>AssertionError</code> <p>If a dimension is required that is not an index in the simplex list</p>"},{"location":"network/#src.connalysis.network.topology.get_k_skeleta_graph--notes","title":"Notes","text":"<p>In order to list k-simplices and thus the k-skeleton, flagsercount needs to list all lower dimensional simplices anyhow.</p> Source code in <code>src/connalysis/network/topology.py</code> <pre><code>def get_k_skeleta_graph(adj=None, max_simplices=False, dimensions=None, simplex_type='directed',\n                        simplex_list=None, N=None, position=\"all\",\n                        **kwargs):\n    # Choose only some dimensions???\n    # check max dim is consistent with simplex_list only used if adj is given and must be &gt;0\n    # adj only used is simplex list is none\n    # Add requirement to give adj is direction is undirected and multiply adj by mat!!!\n\"\"\"Return the edges of the (maximal) k-skeleton of the flag complex of adj for all k&lt;= max_dim in the position determined\n    by position.\n    If simplex list are provided, it will compute the edges directly from these and not use adj,\n    in which case N (the number of rows and columns of adj) is required.\n    If simplex lists are not provided they will be calculated with for the flag complex whose type is determined by\n    simplex_type as for simplex_counts.\n\n    Parameters\n    ----------\n    adj : (N,N)-array or sparse matrix\n        Adjacency matrix of a directed network.  A non-zero entry adj[i,j] implies there is an edge from i to j.\n        The matrix can be asymmetric, but must have 0 in the diagonal.\n    max_simplices : bool\n        If False counts all simplices in adj.\n        If True counts only maximal simplices i.e., simplex motifs that are not contained in higher dimensional ones.\n    dimensions : list of ints\n        Dimensions `k` for which the `k`-skeleta is computed, if None all dimensions are computed.\n    simplex_type : string\n        Type of simplex to consider if computed from adj:\n\n        \u2019directed\u2019 - directed simplices\n\n        \u2019undirected\u2019 - simplices in the underlying undirected graph\n\n        \u2019reciprocal\u2019 - simplices in the undirected graph of reciprocal connections\n    simplex list: series\n        Series 2d-arrays indexed by dimension.\n        Each array is of dimension (no. of simplices, dimension).\n        Each row corresponds to a list of nodes on a simplex.\n        If provided adj will be ignored but N will be required.\n    N: int\n        Number of nodes in original graph.\n    position: str\n        Position of the edges to extract\n\n        'all': all edges of the simplex\n\n        'spine': edges along the spine of the simplex\n        (only makes sense if simplices are directed)\n\n    Returns\n    -------\n    dict\n        Dictionary with keys dimensions and values boolean (N,N) matrices with entries `True`\n        corresponding to edges in (maximal) simplices of that dimension.\n\n    Raises\n    ------\n    AssertionError\n        If neither adj nor simplex_list are provided\n    AssertionError\n        If N &lt;= than an entry in the simplex list\n    AssertionError\n        If a dimension is required that is not an index in the simplex list\n\n    Notes\n    ------\n    In order to list k-simplices and thus the k-skeleton, flagsercount needs to list all lower\n    dimensional simplices anyhow.\n\n    \"\"\"\n\n    assert not (adj is None and simplex_list is None), \"Either adj or simplex_list need to be provided\"\n\n    if dimensions == None:\n        max_dim = -1\n    else:\n        max_dim = np.max(np.array(dimensions))\n\n    if (simplex_list is None):  # Compute simplex lists if not provided\n        simplex_list = list_simplices_by_dimension(adj, node_properties=None,\n                                                   max_simplices=max_simplices, max_dim=max_dim,\n                                                   simplex_type=simplex_type,\n                                                   nodes=None, verbose=False, **kwargs)\n        N = adj.shape[0]\n    else:\n        assert isinstance(N, int), 'If simplex list are provide N must be provided'\n        assert N &gt; np.nanmax(simplex_list.explode().explode()), \\\n            \"N must be larger than all the entries in the simplex list\"\n        assert (dimensions == None) or np.isin(dimensions, simplex_list.index).all(), \\\n            f'Some requested dimensions={dimensions} are not in the simplex lists index={simplex_list.index.to_numpy()}'\n    # Extract 'k'-skeleton\n    dims = simplex_list.index[simplex_list.index != 0]  # Doesn't make sense to look at the 0-skeleton\n    if dimensions != None:\n        dims = dims[np.isin(dims, dimensions)]\n    skeleton_mats = {f'dimension_{dim}': None for dim in dims}\n    for dim in dims:\n        mat = extract_submatrix_of_simplices(simplex_list[dim], N, position=position)\n        if simplex_type in ('undirected', 'reciprocal'):\n            mat = (mat + mat.T).astype(bool)\n        skeleton_mats[f'dimension_{dim}'] = mat\n    return skeleton_mats\n</code></pre>"},{"location":"network/#src.connalysis.network.topology.in_degree_from_pop","title":"<code>in_degree_from_pop(adj, source_pop, max_simplices = False, threads = 1, max_dim = -1, **kwargs)</code>","text":"<p>Compute generalized in-degree of nodes source_pop onto the rest of the nodes in adj.</p> <p>Parameters:</p> Name Type Description Default <code>adj</code> <p>Adjacency matrix of a directed network.  A non-zero entry adj[i,j] implies there is an edge from i to j. The matrix can be asymmetric, but must have 0 in the diagonal.</p> required <code>source_pop</code> required <code>max_simplices</code> <code>bool</code> <p>If False counts all simplices. If True counts only maximal simplices.</p> <code>False</code> <code>max_dim</code> <code>int</code> <p>Maximal dimension up to which simplex motifs are counted. The default max_dim = -1 counts all existing dimensions. Particularly useful for large or dense graphs.</p> <code>-1</code> <p>Returns:</p> Type Description <code>Data frame</code> <p>Table of k-in-degrees from source_pop indexed by the target population.</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If adj restricted to source_pop has non-zero entries in the diagonal which can produce errors.</p> Source code in <code>src/connalysis/network/topology.py</code> <pre><code>def in_degree_from_pop(adj, source_pop, max_simplices=False,threads=1, max_dim=-1, ** kwargs):\n    # TODO: DO THE OUTDEGREE VERSION\n    # TODO: Get participation directly from flagsercount via vertices to do?\n\"\"\"Compute generalized in-degree of nodes source_pop onto the rest of the nodes in adj.\n    Parameters\n    ----------\n    adj: 2d (N,N)-array or sparse matrix\n        Adjacency matrix of a directed network.  A non-zero entry adj[i,j] implies there is an edge from i to j.\n        The matrix can be asymmetric, but must have 0 in the diagonal.\n    source_pop: list of indices of the source population, must be a subset of ``np.arange(0, adj.shape[0])``\n    max_simplices : bool\n        If False counts all simplices.\n        If True counts only maximal simplices.\n    max_dim : int\n        Maximal dimension up to which simplex motifs are counted.\n        The default max_dim = -1 counts all existing dimensions.\n        Particularly useful for large or dense graphs.\n\n    Returns\n    -------\n    Data frame\n        Table of k-in-degrees from source_pop indexed by the target population.\n\n    Raises\n    ------\n    AssertionError\n        If adj restricted to source_pop has non-zero entries in the diagonal which can produce errors.\n    \"\"\"\n    adj=adj.tocsr()\n    source_pop = np.sort(source_pop)\n    target_pop = np.setdiff1d(np.arange(adj.shape[0]), source_pop)\n    adj_source = adj[np.ix_(source_pop, source_pop)]\n    adj_cross = adj[np.ix_(source_pop, target_pop)]\n    degs=cross_col_k_in_degree(adj_cross, adj_source,\n                                 max_simplices=max_simplices,threads=threads, max_dim=max_dim, **kwargs)\n    degs.index=target_pop\n    return degs\n</code></pre>"},{"location":"network/#src.connalysis.network.topology.list_simplices_by_dimension","title":"<code>list_simplices_by_dimension(adj, node_properties = None, max_simplices = False, max_dim = -1, nodes = None, verbose = False, simplex_type = 'directed', **kwargs)</code>","text":"<p>List all simplex motifs in the network adj.</p> <p>Parameters:</p> Name Type Description Default <code>adj</code> <code>2d (N,N)-array or sparse matrix</code> <p>Adjacency matrix of a directed network.  A non-zero entry adj[i,j] implies there is an edge from i to j. The matrix can be asymmetric, but must have 0 in the diagonal.</p> required <code>node_properties</code> <code> data frame</code> <p>Data frame of neuron properties in adj.  Only necessary if used in conjunction with TAP or connectome utilities.</p> <code>None</code> <code>max_simplices</code> <code>bool</code> <p>If False counts all simplices in adj. If True counts only maximal simplices i.e., simplex motifs that are not contained in higher dimensional ones.</p> <code>False</code> <code>max_dim</code> <code>int</code> <p>Maximal dimension up to which simplex motifs are counted. The default max_dim = -1 counts all existing dimensions.  Particularly useful for large or dense graphs.</p> <code>-1</code> <code>simplex_type</code> <code>string</code> <p>Type of simplex to consider:</p> <p>\u2019directed\u2019 - directed simplices</p> <p>\u2019undirected\u2019 - simplices in the underlying undirected graph</p> <p>\u2019reciprocal\u2019 - simplices in the undirected graph of reciprocal connections</p> <code>'directed'</code> <code>nodes</code> <code>1d array or None(default)</code> <p>Restrict to list only the simplices whose source node is in nodes.  If None list all simplices</p> <code>None</code> <p>Returns:</p> Type Description <code>series</code> <p>Simplex lists indexed per dimension.  The dimension k entry is a (no. of k-simplices, k+1)-array is given, where each row denotes a simplex.</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If adj has non-zero entries in the diagonal which can produce errors.</p> <code>AssertionError</code> <p>If adj is not square.</p> <code>AssertionError</code> <p>If nodes is not a subarray of np.arange(N)</p>"},{"location":"network/#src.connalysis.network.topology.list_simplices_by_dimension--see-also","title":"See Also","text":"<p>simplex_counts : A function that counts the simplices instead of listing them and has descriptions of the simplex types.</p> Source code in <code>src/connalysis/network/topology.py</code> <pre><code>def list_simplices_by_dimension(adj, node_properties=None, max_simplices=False,max_dim=-1,nodes=None,\n                                verbose=False, simplex_type='directed', **kwargs):\n\"\"\"List all simplex motifs in the network adj.\n    Parameters\n    ----------\n    adj : 2d (N,N)-array or sparse matrix\n        Adjacency matrix of a directed network.  A non-zero entry adj[i,j] implies there is an edge from i to j.\n        The matrix can be asymmetric, but must have 0 in the diagonal.\n    node_properties :  data frame\n        Data frame of neuron properties in adj.  Only necessary if used in conjunction with TAP or connectome utilities.\n    max_simplices : bool\n        If False counts all simplices in adj.\n        If True counts only maximal simplices i.e., simplex motifs that are not contained in higher dimensional ones.\n    max_dim : int\n        Maximal dimension up to which simplex motifs are counted.\n        The default max_dim = -1 counts all existing dimensions.  Particularly useful for large or dense graphs.\n    simplex_type : string\n        Type of simplex to consider:\n\n        \u2019directed\u2019 - directed simplices\n\n        \u2019undirected\u2019 - simplices in the underlying undirected graph\n\n        \u2019reciprocal\u2019 - simplices in the undirected graph of reciprocal connections\n    nodes : 1d array or None(default)\n        Restrict to list only the simplices whose source node is in nodes.  If None list all simplices\n\n    Returns\n    -------\n    series\n        Simplex lists indexed per dimension.  The dimension k entry is a (no. of k-simplices, k+1)-array\n        is given, where each row denotes a simplex.\n\n    Raises\n    ------\n    AssertionError\n        If adj has non-zero entries in the diagonal which can produce errors.\n    AssertionError\n        If adj is not square.\n    AssertionError\n        If nodes is not a subarray of np.arange(N)\n\n    See Also\n    --------\n    simplex_counts : A function that counts the simplices instead of listing them and has descriptions of the\n    simplex types.\n    \"\"\"\n    LOG.info(\"COMPUTE list of %ssimplices by dimension\", \"max-\" if max_simplices else \"\")\n\n    import pyflagsercount\n\n    adj=sp.csr_matrix(adj)\n    assert np.count_nonzero(adj.diagonal()) == 0, 'The diagonal of the matrix is non-zero and this may lead to errors!'\n    N, M = adj.shape\n    assert N == M, 'Dimension mismatch. The matrix must be square.'\n    if not nodes is None:\n        assert np.isin(nodes,np.arange(N)).all(), \"nodes must be a subarray of the nodes of the matrix\"\n\n    #Symmetrize matrix if simplex_type is not 'directed'\n    if simplex_type=='undirected':\n        adj=sp.triu(underlying_undirected_matrix(adj)) #symmtrize and keep upper triangular only\n    elif simplex_type==\"reciprocal\":\n        adj=sp.triu(rc_submatrix(adj)) #symmtrize and keep upper triangular only\n\n    n_threads = kwargs.get(\"threads\", kwargs.get(\"n_threads\", 1))\n\n\n    # Only the simplices that have sources stored in this temporary file will be considered\n    if not nodes is None:\n        import tempfile\n        import os\n        tmp_file = tempfile.NamedTemporaryFile(delete=False)\n        vertices_todo = tmp_file.name + \".npy\"\n        np.save(vertices_todo, nodes, allow_pickle=False)\n    else:\n        vertices_todo=''\n\n    #Generate simplex_list\n    original=pyflagsercount.flagser_count(adj, max_simplices=max_simplices,threads=n_threads,max_dim=max_dim,\n                                      vertices_todo=vertices_todo, return_simplices=True)['simplices']\n\n    #Remove temporary file\n    if not nodes is None:\n        os.remove(vertices_todo)\n\n    #Format output\n    max_dim = len(original)\n    dims = pd.Index(np.arange(max_dim), name=\"dim\")\n    simplices = pd.Series(original, name=\"simplices\", index=dims).apply(np.array)\n    #When counting all simplices flagser doesn't list dim 0 and 1 because they correspond to vertices and edges\n    if not max_simplices:\n        if nodes is None:\n            nodes=np.arange(0, N)\n        coom = adj.tocoo()\n        simplices[0] = np.reshape(nodes, (nodes.size, 1))\n        mask=np.isin(coom.row,nodes)\n        simplices[1] = np.stack([coom.row[mask], coom.col[mask]]).T\n    return simplices\n</code></pre>"},{"location":"network/#src.connalysis.network.topology.node_degree","title":"<code>node_degree(adj, node_properties = None, direction = None, weighted = False, **kwargs)</code>","text":"<p>Compute degree of nodes in network adj</p> <p>Parameters:</p> Name Type Description Default <code>adj</code> <code>2d array or sparse matrix</code> <p>Adjacency matrix of the directed network.  A non-zero entry adj[i,j] implies there is an edge from i to j of weight adj[i,j].</p> required <code>node_properties</code> <code>data frame</code> <p>Data frame of neuron properties in adj. Only necessary if used in conjunction with TAP or connectome utilities.</p> <code>None</code> <code>direction</code> <code>string or tuple of strings</code> <p>Direction for which to compute the degree</p> <p>'IN' - In degree</p> <p>'OUT'- Out degree</p> <p>None or ('IN', 'OUT') - Total degree i.e. IN+OUT</p> <code>None</code> <p>Returns:</p> Type Description <code>series or data frame</code> <p>Raises:</p> Type Description <code>Warning</code> <p>If adj has non-zero entries in the diagonal</p> <code>AssertionError</code> <p>If direction is invalid</p> Source code in <code>src/connalysis/network/topology.py</code> <pre><code>def node_degree(adj, node_properties=None, direction=None, weighted=False, **kwargs):\n\"\"\"Compute degree of nodes in network adj\n    Parameters\n    ----------\n    adj : 2d array or sparse matrix\n        Adjacency matrix of the directed network.  A non-zero entry adj[i,j] implies there is an edge from i to j\n        of weight adj[i,j].\n    node_properties : data frame\n        Data frame of neuron properties in adj. Only necessary if used in conjunction with TAP or connectome utilities.\n    direction : string or tuple of strings\n        Direction for which to compute the degree\n\n        'IN' - In degree\n\n        'OUT'- Out degree\n\n        None or ('IN', 'OUT') - Total degree i.e. IN+OUT\n\n    Returns\n    -------\n    series or data frame\n\n    Raises\n    ------\n    Warning\n        If adj has non-zero entries in the diagonal\n    AssertionError\n        If direction is invalid\n    \"\"\"\n    assert not direction or direction in (\"IN\", \"OUT\") or tuple(direction) == (\"IN\", \"OUT\"),\\\n        f\"Invalid `direction`: {direction}\"\n\n    if not isinstance(adj, np. ndarray):\n        matrix = adj.toarray()\n    else:\n        matrix=adj.copy()\n    if not weighted:\n        matrix=matrix.astype('bool')\n    if np.count_nonzero(np.diag(matrix)) != 0:\n        logging.warning('The diagonal is non-zero!  This may cause errors in the analysis')\n    index = pd.Series(range(matrix.shape[0]), name=\"node\")\n    series = lambda array: pd.Series(array, index)\n    in_degree = lambda: series(matrix.sum(axis=0))\n    out_degree = lambda: series(matrix.sum(axis=1))\n\n    if not direction:\n        return in_degree() + out_degree()\n\n    if tuple(direction) == (\"IN\", \"OUT\"):\n        return pd.DataFrame({\"IN\": in_degree(), \"OUT\": out_degree()})\n\n    if tuple(direction) == (\"OUT\", \"IN\"):\n        return pd.DataFrame({\"OUT\": out_degree(), \"IN\": in_degree()})\n\n    return in_degree() if direction == \"IN\" else out_degree()\n</code></pre>"},{"location":"network/#src.connalysis.network.topology.node_k_degree","title":"<code>node_k_degree(adj, node_properties = None, direction = ('IN', 'OUT'), max_dim = -1, **kwargs)</code>","text":"<p>Compute generalized degree of nodes in network adj.  The k-(in/out)-degree of a node v is the number of k-simplices with all its nodes mapping to/from the node v.</p> <p>Parameters:</p> Name Type Description Default <code>adj</code> <code>2d array or sparse matrix</code> <p>Adjacency matrix of the directed network.  A non-zero entry adj[i,j] implies there is an edge from i to j of weight adj[i,j].  The matrix can be asymmetric, but must have 0 in the diagonal.</p> required <code>node_properties</code> <code>dataframe</code> <p>Data frame of neuron properties in adj.  Only necessary if used in conjunction with TAP or connectome utilities.</p> <code>None</code> <code>direction</code> <code>string</code> <p>Direction for which to compute the degree</p> <p>'IN' - In degree</p> <p>'OUT'- Out degree</p> <p>(\u2019IN\u2019, \u2019OUT\u2019) - both</p> <code>('IN', 'OUT')</code> <code>max_dim</code> <code>int</code> <p>Maximal dimension for which to compute the degree max_dim &gt;=2 or -1 in which case it computes all dimensions.</p> <code>-1</code> <p>Returns:</p> Type Description <code>data frame</code> <p>Table of of k-(in/out)-degrees</p> <p>Raises:</p> Type Description <code>Warning</code> <p>If adj has non-zero entries in the diagonal which are ignored in the analysis</p> <code>AssertionError</code> <p>If direction is invalid</p> <code>AssertionError</code> <p>If not max_dim &gt;1</p>"},{"location":"network/#src.connalysis.network.topology.node_k_degree--notes","title":"Notes","text":"<p>Note that the k-in-degree of a node v is the number of (k+1) simplices the node v is a sink of. Dually, the k-out-degree of a node v is the number of (k+1) simplices the node v is a source of.</p> Source code in <code>src/connalysis/network/topology.py</code> <pre><code>def node_k_degree(adj, node_properties=None, direction=(\"IN\", \"OUT\"), max_dim=-1, **kwargs):\n    #TODO: Generalize from one population to another\n\"\"\"Compute generalized degree of nodes in network adj.  The k-(in/out)-degree of a node v is the number of\n    k-simplices with all its nodes mapping to/from the node v.\n    Parameters\n    ----------\n    adj : 2d array or sparse matrix\n        Adjacency matrix of the directed network.  A non-zero entry adj[i,j] implies there is an edge from i to j\n        of weight adj[i,j].  The matrix can be asymmetric, but must have 0 in the diagonal.\n    node_properties : dataframe\n        Data frame of neuron properties in adj.  Only necessary if used in conjunction with TAP or connectome utilities.\n    direction : string\n        Direction for which to compute the degree\n\n        'IN' - In degree\n\n        'OUT'- Out degree\n\n        (\u2019IN\u2019, \u2019OUT\u2019) - both\n    max_dim : int\n        Maximal dimension for which to compute the degree max_dim &gt;=2 or -1 in\n        which case it computes all dimensions.\n\n    Returns\n    -------\n    data frame\n        Table of of k-(in/out)-degrees\n\n    Raises\n    ------\n    Warning\n        If adj has non-zero entries in the diagonal which are ignored in the analysis\n    AssertionError\n        If direction is invalid\n    AssertionError\n        If not max_dim &gt;1\n\n    Notes\n    -----\n    Note that the k-in-degree of a node v is the number of (k+1) simplices the node v is a sink of.\n    Dually, the k-out-degree of a node v is the number of (k+1) simplices the node v is a source of.\n    \"\"\"\n    matrix = sp.csr_matrix(adj)\n    assert (max_dim &gt; 1) or (max_dim==-1), \"max_dim should be &gt;=2\"\n    assert direction in (\"IN\", \"OUT\") or tuple(direction) == (\"IN\", \"OUT\"), \\\n        f\"Invalid `direction`: {direction}\"\n    if np.count_nonzero(matrix.diagonal()) != 0:\n        logging.warning('The diagonal is non-zero!  Non-zero entries in the diagonal will be ignored.')\n    import pyflagsercount\n    flagser_out = pyflagsercount.flagser_count(matrix, return_simplices=True, max_dim=max_dim)\n    max_dim_possible = len(flagser_out['cell_counts']) - 1\n    if max_dim==-1:\n        max_dim = max_dim_possible\n    elif max_dim &gt; max_dim_possible:\n        logging.warning(\"The maximum dimension selected is not attained\")\n        max_dim = max_dim_possible\n    if (max_dim &lt;= 1) and (max_dim!=-1):\n        print(\"There are no simplices of dimension 2 or higher\")\n    else:\n        index = pd.Series(range(matrix.shape[0]), name=\"node\")\n        generalized_degree = pd.DataFrame(index=index)\n        for dim in np.arange(2, max_dim + 1):\n            if \"OUT\" in direction:\n                # getting source participation across dimensions\n                x, y = np.unique(np.array(flagser_out['simplices'][dim])[:, 0], return_counts=True)\n                generalized_degree[f'{dim}_out_degree'] = pd.Series(y, index=x)\n            if \"IN\" in direction:\n                # getting sink participation across dimensions\n                x, y = np.unique(np.array(flagser_out['simplices'][dim])[:, dim], return_counts=True)\n                generalized_degree[f'{dim}_in_degree'] = pd.Series(y, index=x)\n        return generalized_degree.fillna(0)\n</code></pre>"},{"location":"network/#src.connalysis.network.topology.node_participation","title":"<code>node_participation(adj, node_properties = None, max_simplices = False, threads = 1, max_dim = -1, simplex_type = 'directed', **kwargs)</code>","text":"<p>Compute the number of simplex motifs in the network adj each node is part of. See simplex_counts for details.</p> <p>Parameters:</p> Name Type Description Default <code>adj</code> <code>2d array or sparse matrix</code> <p>Adjacency matrix of the directed network.  A non-zero entry adj[i,j] implies there is an edge from i to j. The matrix can be asymmetric, but must have 0 in the diagonal.</p> required <code>node_properties</code> <code>dataframe</code> <p>Data frame of neuron properties in adj.  Only necessary if used in conjunction with TAP or connectome utilities.</p> <code>None</code> <code>max_simplices</code> <code>bool</code> <p>If False (default) counts all simplices in adj. If True counts only maximal simplices i.e., simplex motifs that are not contained in higher dimensional ones.</p> <code>False</code> <code>max_dim</code> <code>int</code> <p>Maximal dimension up to which simplex motifs are counted. The default max_dim = -1 counts all existing dimensions.  Particularly useful for large or dense graphs.</p> <code>-1</code> <code>simplex_type</code> <code>string</code> <p>Type of simplex to consider:</p> <p>\u2019directed\u2019 - directed simplices</p> <p>\u2019undirected\u2019 - simplices in the underlying undirected graph</p> <p>\u2019reciprocal\u2019 - simplices in the undirected graph of reciprocal connections</p> <code>'directed'</code> <p>Returns:</p> Type Description <code>data frame</code> <p>Indexed by the nodes in adj and with columns de dimension for which node participation is counted</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If adj has non-zero entries in the diagonal which can produce errors.</p> <code>AssertionError</code> <p>If adj is not square.</p> Source code in <code>src/connalysis/network/topology.py</code> <pre><code>def node_participation(adj, node_properties=None, max_simplices=False,\n                       threads=1,max_dim=-1,simplex_type='directed',**kwargs):\n\"\"\"Compute the number of simplex motifs in the network adj each node is part of.\n    See simplex_counts for details.\n    Parameters\n    ----------\n    adj : 2d array or sparse matrix\n        Adjacency matrix of the directed network.  A non-zero entry adj[i,j] implies there is an edge from i to j.\n        The matrix can be asymmetric, but must have 0 in the diagonal.\n    node_properties : dataframe\n        Data frame of neuron properties in adj.  Only necessary if used in conjunction with TAP or connectome utilities.\n    max_simplices : bool\n        If False (default) counts all simplices in adj.\n        If True counts only maximal simplices i.e., simplex motifs that are not contained in higher dimensional ones.\n    max_dim : int\n        Maximal dimension up to which simplex motifs are counted.\n        The default max_dim = -1 counts all existing dimensions.  Particularly useful for large or dense graphs.\n    simplex_type : string\n        Type of simplex to consider:\n\n        \u2019directed\u2019 - directed simplices\n\n        \u2019undirected\u2019 - simplices in the underlying undirected graph\n\n        \u2019reciprocal\u2019 - simplices in the undirected graph of reciprocal connections\n\n    Returns\n    -------\n    data frame\n        Indexed by the nodes in adj and with columns de dimension for which node participation is counted\n\n    Raises\n    -------\n    AssertionError\n        If adj has non-zero entries in the diagonal which can produce errors.\n    AssertionError\n        If adj is not square.\n    \"\"\"\n\n    adj=sp.csr_matrix(adj).astype('bool')\n    assert np.count_nonzero(adj.diagonal()) == 0, 'The diagonal of the matrix is non-zero and this may lead to errors!'\n    N, M = adj.shape\n    assert N == M, 'Dimension mismatch. The matrix must be square.'\n\n\n    #Symmetrize matrix if simplex_type is not 'directed'\n    if simplex_type=='undirected':\n        adj=sp.triu(underlying_undirected_matrix(adj)) #symmtrize and keep upper triangular only\n    elif simplex_type==\"reciprocal\":\n        adj=sp.triu(rc_submatrix(adj)) #symmtrize and keep upper triangular only\n\n    flagser_counts = _flagser_counts(adj, count_node_participation=True, threads=threads,\n                                     max_simplices=max_simplices, max_dim=max_dim)\n    return flagser_counts[\"node_participation\"]\n</code></pre>"},{"location":"network/#src.connalysis.network.topology.normalized_simplex_counts","title":"<code>normalized_simplex_counts(adj, node_properties = None, max_simplices = False, threads = 1, max_dim = -1, **kwargs)</code>","text":"<p>Compute the ratio of directed/undirected simplex counts normalized to be between 0 and 1. See simplex_counts and undirected_simplex_counts for details.</p> <p>Parameters:</p> Name Type Description Default <code>adj</code> <code>2d array or sparse matrix</code> <p>Adjacency matrix of the directed network.  A non-zero entry adj[i,j] implies there is an edge from i to j of weight adj[i,j].  The matrix can be asymmetric, but must have 0 in the diagonal.</p> required <code>node_properties</code> <code>dataframe</code> <p>Data frame of neuron properties in adj.  Only necessary if used in conjunction with TAP or connectome utilities.</p> <code>None</code> <code>max_simplices</code> <code>bool</code> <p>If False counts all simplices in adj. If True counts only maximal simplices i.e., simplex motifs that are not contained in higher dimensional ones.</p> <code>False</code> <code>max_dim</code> <code>int</code> <p>Maximal dimension up to which simplex motifs are counted. The default max_dim = -1 counts all existing dimensions.  Particularly useful for large or dense graphs.</p> <code>-1</code> <p>Returns:</p> Type Description <code>panda series</code> <p>Normalized simplex counts</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If adj has non-zero entries in the diagonal which can produce errors.</p>"},{"location":"network/#src.connalysis.network.topology.normalized_simplex_counts--notes","title":"Notes","text":"<p>Maybe we should say why we choose this metric</p> Source code in <code>src/connalysis/network/topology.py</code> <pre><code>def normalized_simplex_counts(adj, node_properties=None,\n                   max_simplices=False, threads=1,max_dim=-1,\n                   **kwargs):\n\"\"\"Compute the ratio of directed/undirected simplex counts normalized to be between 0 and 1.\n    See simplex_counts and undirected_simplex_counts for details.\n    Parameters\n    ----------\n    adj : 2d array or sparse matrix\n        Adjacency matrix of the directed network.  A non-zero entry adj[i,j] implies there is an edge from i to j\n        of weight adj[i,j].  The matrix can be asymmetric, but must have 0 in the diagonal.\n    node_properties : dataframe\n        Data frame of neuron properties in adj.  Only necessary if used in conjunction with TAP or connectome utilities.\n    max_simplices : bool\n        If False counts all simplices in adj.\n        If True counts only maximal simplices i.e., simplex motifs that are not contained in higher dimensional ones.\n    max_dim : int\n        Maximal dimension up to which simplex motifs are counted.\n        The default max_dim = -1 counts all existing dimensions.  Particularly useful for large or dense graphs.\n\n    Returns\n    -------\n    panda series\n        Normalized simplex counts\n\n    Raises\n    ------\n    AssertionError\n        If adj has non-zero entries in the diagonal which can produce errors.\n\n    Notes\n    -----\n    Maybe we should say why we choose this metric\"\"\"\n\n    from scipy.special import factorial\n    denominator=simplex_counts(adj, node_properties=node_properties,max_simplices=max_simplices,\n                                          threads=threads,max_dim=max_dim,simplex_type='undirected', **kwargs).to_numpy()\n    #Global maximum dimension since every directed simplex has an underlying undirected one of the same dimension\n    max_dim_global=denominator.size\n    #Maximum number of possible directed simplices for each undirected simplex across dimensions\n    max_possible_directed=np.array([factorial(i+1) for i in np.arange(max_dim_global)])\n    denominator=np.multiply(denominator, max_possible_directed)\n    numerator=simplex_counts(adj, node_properties=node_properties,max_simplices=max_simplices,\n                             threads=threads,max_dim=max_dim,simple_type='directed', **kwargs).to_numpy()\n    numerator=np.pad(numerator, (0, max_dim_global-len(numerator)), 'constant', constant_values=0)\n    return _series_by_dim(np.divide(numerator,denominator)[1:],name=\"normalized_simplex_counts\",\n                          index=np.arange(1,max_dim_global), name_index=\"dim\")\n</code></pre>"},{"location":"network/#src.connalysis.network.topology.rc_submatrix","title":"<code>rc_submatrix(adj)</code>","text":"<p>Returns the symmetric submatrix of reciprocal connections of adj</p> <p>Parameters:</p> Name Type Description Default <code>adj</code> <code>2d array or sparse matrix</code> <p>Adjacency matrix of the directed network.  A non-zero entry adj[i,j] implies there is an edge from i to j.</p> required <p>Returns:</p> Type Description <code>sparse matrix</code> <p>symmetric matrix of the same dtype as adj of reciprocal connections</p> Source code in <code>src/connalysis/network/topology.py</code> <pre><code>def rc_submatrix(adj):\n\"\"\"Returns the symmetric submatrix of reciprocal connections of adj\n    Parameters\n    ----------\n    adj : 2d array or sparse matrix\n        Adjacency matrix of the directed network.  A non-zero entry adj[i,j] implies there is an edge from i to j.\n\n    Returns\n    -------\n    sparse matrix\n        symmetric matrix of the same dtype as adj of reciprocal connections\n    \"\"\"\n    adj=sp.csr_matrix(adj)\n    if np.count_nonzero(adj.diagonal()) != 0:\n        logging.warning('The diagonal is non-zero and this may lead to errors!')\n    mask=adj.copy().astype('bool')\n    mask=(mask.multiply(mask.T))\n    mask.eliminate_zeros\n    return adj.multiply(mask).astype(adj.dtype)\n</code></pre>"},{"location":"network/#src.connalysis.network.topology.simplex_counts","title":"<code>simplex_counts(adj, node_properties = None, max_simplices = False, threads = 1, max_dim = -1, simplex_type = 'directed', **kwargs)</code>","text":"<p>Compute the number of simplex motifs in the network adj.</p> <p>Parameters:</p> Name Type Description Default <code>adj</code> <code>2d array or sparse matrix</code> <p>Adjacency matrix of the directed network.  A non-zero entry adj[i,j] implies there is an edge from i to j of weight adj[i,j].  The matrix can be asymmetric, but must have 0 in the diagonal.</p> required <code>node_properties</code> <code>dataframe</code> <p>Data frame of neuron properties in adj.  Only necessary if used in conjunction with TAP or connectome utilities.</p> <code>None</code> <code>max_simplices</code> <code>bool</code> <p>If False counts all simplices in adj. If True counts only maximal simplices i.e., simplex motifs that are not contained in higher dimensional ones.</p> <code>False</code> <code>max_dim</code> <code>int</code> <p>Maximal dimension up to which simplex motifs are counted. The default max_dim = -1 counts all existing dimensions.  Particularly useful for large or dense graphs.</p> <code>-1</code> <code>simplex_type</code> <p>Type of simplex to consider (See Notes):</p> <p>\u2019directed\u2019 - directed simplices</p> <p>\u2019undirected\u2019 - simplices in the underlying undirected graph</p> <p>\u2019reciprocal\u2019 - simplices in the undirected graph of reciprocal connections</p> <code>'directed'</code> <p>Returns:</p> Type Description <code>series</code> <p>simplex counts</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If adj has non-zero entries in the diagonal which can produce errors.</p> <code>AssertionError</code> <p>If adj is not square.</p>"},{"location":"network/#src.connalysis.network.topology.simplex_counts--notes","title":"Notes","text":"<p>A directed simplex of dimension k in adj is a set of (k+1) nodes which are all to all connected in a feedforward manner. That is, they can be ordered from 0 to k such that there is an edge from i to j whenever i &lt; j.</p> <p>An undirected simplex of dimension k in adj is a set of (k+1) nodes in adj which are all to all connected.  That is, they are all to all connected in the underlying undirected graph of adj.  In the literature this is also called a (k+1)-clique of the underlying undirected graph.</p> <p>A reciprocal simplex of dimension k in adj is a set of (k+1) nodes in adj which are all to all reciprocally connected. That is, they are all to all connected in the undirected graph of reciprocal connections of adj.  In the literature this is also called a (k+1)-clique of the undirected graph of reciprocal connections.</p> Source code in <code>src/connalysis/network/topology.py</code> <pre><code>def simplex_counts(adj, node_properties=None,max_simplices=False,\n                   threads=1,max_dim=-1, simplex_type='directed', **kwargs):\n\"\"\"Compute the number of simplex motifs in the network adj.\n    Parameters\n    ----------\n    adj : 2d array or sparse matrix\n        Adjacency matrix of the directed network.  A non-zero entry adj[i,j] implies there is an edge from i to j\n        of weight adj[i,j].  The matrix can be asymmetric, but must have 0 in the diagonal.\n    node_properties : dataframe\n        Data frame of neuron properties in adj.  Only necessary if used in conjunction with TAP or connectome utilities.\n    max_simplices : bool\n        If False counts all simplices in adj.\n        If True counts only maximal simplices i.e., simplex motifs that are not contained in higher dimensional ones.\n    max_dim : int\n        Maximal dimension up to which simplex motifs are counted.\n        The default max_dim = -1 counts all existing dimensions.  Particularly useful for large or dense graphs.\n    simplex_type: string\n        Type of simplex to consider (See Notes):\n\n        \u2019directed\u2019 - directed simplices\n\n        \u2019undirected\u2019 - simplices in the underlying undirected graph\n\n        \u2019reciprocal\u2019 - simplices in the undirected graph of reciprocal connections\n\n    Returns\n    -------\n    series\n        simplex counts\n\n    Raises\n    ------\n    AssertionError\n        If adj has non-zero entries in the diagonal which can produce errors.\n    AssertionError\n        If adj is not square.\n\n    Notes\n    -----\n    A directed simplex of dimension k in adj is a set of (k+1) nodes which are all to all connected in a feedforward manner.\n    That is, they can be ordered from 0 to k such that there is an edge from i to j whenever i &lt; j.\n\n    An undirected simplex of dimension k in adj is a set of (k+1) nodes in adj which are all to all connected.  That is, they\n    are all to all connected in the underlying undirected graph of adj.  In the literature this is also called a (k+1)-clique\n    of the underlying undirected graph.\n\n    A reciprocal simplex of dimension k in adj is a set of (k+1) nodes in adj which are all to all reciprocally connected.\n    That is, they are all to all connected in the undirected graph of reciprocal connections of adj.  In the literature this is\n    also called a (k+1)-clique of the undirected graph of reciprocal connections.\n    \"\"\"\n    adj=sp.csr_matrix(adj)\n    assert np.count_nonzero(adj.diagonal()) == 0, 'The diagonal of the matrix is non-zero and this may lead to errors!'\n    N, M = adj.shape\n    assert N == M, 'Dimension mismatch. The matrix must be square.'\n\n\n    #Symmetrize matrix if simplex_type is not 'directed'\n    if simplex_type=='undirected':\n        adj=sp.triu(underlying_undirected_matrix(adj)) #symmtrize and keep upper triangular only\n    elif simplex_type==\"reciprocal\":\n        adj=sp.triu(rc_submatrix(adj)) #symmtrize and keep upper triangular only\n\n    flagser_counts = _flagser_counts(adj, threads=threads, max_simplices=max_simplices, max_dim=max_dim)\n    if max_simplices:\n        return flagser_counts[\"max_simplex_counts\"]\n    else:\n        return flagser_counts[\"simplex_counts\"]\n</code></pre>"},{"location":"network/#src.connalysis.network.topology.simplicial_rich_club_curve","title":"<code>simplicial_rich_club_curve(M, maximal = False, sparse_bin_set = False)</code>","text":"<p>Computes the simplicial rich club curve of a network.    Where the i'th entry is the density of the subnetwork induced by the vertices that are contained in    more than i (maximal) simplices.</p> <p>Parameters:</p> Name Type Description Default <code>adj</code> <code>2d-array</code> <p>Adjacency matrix of a directed network.</p> required <code>max_simplices</code> <code>bool</code> <p>If true then vertex participation is the number of maximal simplices each vertex is contained in.</p> required <code>sparse_bin_set</code> <code>bool</code> <p>If true then consecutive entries with same rich club coefficient are grouped into bins together,</p> <code>False</code> <p>Returns:</p> Type Description <code>pandas.Series</code> <p>Where the i'th entry is the rich club coefficient of the network induced by all vertices which are contained in more that i (maximal) simplices</p> Source code in <code>src/connalysis/network/topology.py</code> <pre><code>def simplicial_rich_club_curve(M, maximal=False, sparse_bin_set=False):\n\"\"\"Computes the simplicial rich club curve of a network.\n           Where the i'th entry is the density of the subnetwork induced by the vertices that are contained in\n           more than i (maximal) simplices.\n\n        Parameters\n        ----------\n        adj : 2d-array\n            Adjacency matrix of a directed network.\n        max_simplices : bool\n            If true then vertex participation is the number of maximal simplices each vertex is contained in.\n        sparse_bin_set : bool\n            If true then consecutive entries with same rich club coefficient are grouped into bins together,\n\n        Returns\n        -------\n        pandas.Series\n            Where the i'th entry is the rich club coefficient of the network induced by all vertices which are\n            contained in more that i (maximal) simplices\n\n    \"\"\"\n    import pyflagsercount\n    from .classic import efficient_rich_club_curve\n    vertex_par = pd.DataFrame(pyflagsercount.flagser_count(M, max_simplices=maximal, containment=True)['contain_counts']).replace(np.nan,0).astype(int)\n    return pd.DataFrame([efficient_rich_club_curve(M, pre_calculated_richness=vertex_par[i]) for i in range(vertex_par.shape[1])]).transpose().dropna(how='all')\n</code></pre>"},{"location":"network/#src.connalysis.network.topology.underlying_undirected_matrix","title":"<code>underlying_undirected_matrix(adj)</code>","text":"<p>Returns the symmetric matrix of undirected connections of <code>adj</code>.</p> <p>Parameters:</p> Name Type Description Default <code>adj</code> <code>2d array or sparse matrix</code> <p>Adjacency matrix of the directed network.  A non-zero entry in <code>adj[i][j]</code> implies there is an edge from vertex <code>i</code> to vertex <code>j</code>.</p> required <p>Returns:</p> Type Description <code>sparse boolean matrix</code> <p>Corresponding to the symmetric underlying undirected graph</p> Source code in <code>src/connalysis/network/topology.py</code> <pre><code>def underlying_undirected_matrix(adj):\n\"\"\"Returns the symmetric matrix of undirected connections of `adj`.\n    Parameters\n    ----------\n    adj : 2d array or sparse matrix\n        Adjacency matrix of the directed network.  A non-zero entry in `adj[i][j]` implies there is an edge from vertex `i` to vertex `j`.\n\n    Returns\n    -------\n    sparse boolean matrix\n        Corresponding to the symmetric underlying undirected graph\n    \"\"\"\n    adj=sp.csr_matrix(adj)\n    if np.count_nonzero(adj.diagonal()) != 0:\n        logging.warning('The diagonal is non-zero and this may lead to errors!')\n    return (adj+adj.T).astype('bool')\n</code></pre>"},{"location":"network/#graph-theory","title":"Graph theory","text":"<p>These functions are classic graph theoretic functions.</p>"},{"location":"network/#src.connalysis.network.classic.centrality","title":"<code>centrality(self, sub_gids, kind = 'closeness', directed = False)</code>","text":"<p>Compute a centrality of the graph. <code>kind</code> can be 'betweeness' or 'closeness'</p> Source code in <code>src/connalysis/network/classic.py</code> <pre><code>def centrality(self, sub_gids, kind=\"closeness\", directed=False):\n\"\"\"Compute a centrality of the graph. `kind` can be 'betweeness' or 'closeness'\"\"\"\n    if kind == \"closeness\":\n        return self.closeness(sub_gids, directed)\n    else:\n        ValueError(\"Kind must be 'closeness'!\")\n</code></pre>"},{"location":"network/#src.connalysis.network.classic.closeness","title":"<code>closeness(adj, neuron_properties, directed = False)</code>","text":"<p>Compute closeness centrality using sknetwork on all connected components or strongly connected component (if directed==True)</p> Source code in <code>src/connalysis/network/classic.py</code> <pre><code>def closeness(adj, neuron_properties, directed=False):\n\"\"\"Compute closeness centrality using sknetwork on all connected components or strongly connected\n    component (if directed==True)\"\"\"\n    return closeness_connected_components(adj, directed=directed)\n</code></pre>"},{"location":"network/#src.connalysis.network.classic.closeness_connected_components","title":"<code>closeness_connected_components(adj, neuron_properties = [], directed = False, return_sum = True)</code>","text":"<p>Compute the closeness of each connected component of more than 1 vertex</p> <p>Parameters:</p> Name Type Description Default <code>adj</code> <code>array_like</code> <p>Adjacency matrix of the graph</p> required <code>directed</code> <code>bool</code> <p>If <code>True</code>, will be computed using strongly connected components and directed closeness.</p> <code>False</code> <code>return_sum</code> <code>bool</code> <p>If <code>True</code>, only one list will be returned, by summing over all the connected components.</p> <code>True</code> <p>Returns:</p> Type Description <code>array_like</code> <p>A single array( if <code>return_sum=True</code>) or a list of arrays of shape <code>n</code>, containting closeness of vertices in that component, or 0 if the vertex is not in the component. Closeness cannot be zero otherwise.</p> Source code in <code>src/connalysis/network/classic.py</code> <pre><code>def closeness_connected_components(adj, neuron_properties=[], directed=False, return_sum=True):\n\"\"\"Compute the closeness of each connected component of more than 1 vertex\n\n    Parameters\n    ----------\n    adj : array_like\n        Adjacency matrix of the graph\n    directed : bool\n        If `True`, will be computed using strongly connected components and directed closeness.\n    return_sum : bool\n        If `True`, only one list will be returned, by summing over all the connected components.\n\n\n    Returns\n    -------\n    array_like\n        A single array( if `return_sum=True`) or a list of arrays of shape `n`, containting closeness of vertices in that component, or 0 if the vertex is not in the component. Closeness cannot be zero otherwise.\n\n    \"\"\"\n    import numpy as np\n    from sknetwork.ranking import Closeness\n    from scipy.sparse.csgraph import connected_components\n\n    matrix=adj.toarray()\n    if directed:\n        n_comp, comp = connected_components(matrix, directed=True, connection=\"strong\")\n    else:\n        n_comp, comp = connected_components(matrix, directed=False)\n        matrix = matrix + matrix.T  # we need to make the matrix symmetric\n\n    closeness = Closeness()  # if matrix is not symmetric automatically use directed\n    n = matrix.shape[0]\n    all_c = []\n    for i in range(n_comp):\n        c = np.zeros(n)\n        idx = np.where(comp == i)[0]\n        sub_mat = matrix[np.ix_(idx, idx)].tocsr()\n        if sub_mat.getnnz() &gt; 0:\n            c[idx] = closeness.fit_transform(sub_mat)\n            all_c.append(c)\n    if return_sum:\n        all_c = np.array(all_c)\n        return np.sum(all_c, axis=0)\n    else:\n        return all_c\n</code></pre>"},{"location":"network/#src.connalysis.network.classic.connected_components","title":"<code>connected_components(adj, neuron_properties = [])</code>","text":"<p>Returns a list of the size of the connected components of the underlying undirected graph on sub_gids, if None, compute on the whole graph</p> Source code in <code>src/connalysis/network/classic.py</code> <pre><code>def connected_components(adj,neuron_properties=[]):\n\"\"\"Returns a list of the size of the connected components of the underlying undirected graph on sub_gids,\n    if None, compute on the whole graph\"\"\"\n    import networkx as nx\n    import numpy as np\n\n    matrix=adj.toarray()\n    matrix_und = np.where((matrix+matrix.T) &gt;= 1, 1, 0)\n    # TODO: Change the code from below to scipy implementation that seems to be faster!\n    G = nx.from_numpy_matrix(matrix_und)\n    return [len(c) for c in sorted(nx.connected_components(G), key=len, reverse=True)]\n</code></pre>"},{"location":"network/#src.connalysis.network.classic.core_number","title":"<code>core_number(adj, neuron_properties = [])</code>","text":"<p>Returns k core of directed graph, where degree of a vertex is the sum of in degree and out degree</p> Source code in <code>src/connalysis/network/classic.py</code> <pre><code>def core_number(adj, neuron_properties=[]):\n\"\"\"Returns k core of directed graph, where degree of a vertex is the sum of in degree and out degree\"\"\"\n    # TODO: Implement directed (k,l) core and k-core of underlying undirected graph (very similar to this)\n    import networkx\n    G = networkx.from_numpy_matrix(adj.toarray())\n    # Very inefficient (returns a dictionary!). TODO: Look for different implementation\n    return networkx.algorithms.core.core_number(G)\n</code></pre>"},{"location":"network/#src.connalysis.network.classic.generate_degree_based_control","title":"<code>generate_degree_based_control(M, direction = 'efferent')</code>","text":"<p>A shuffled version of a connectivity matrix that aims to preserve degree distributions. If direction = \"efferent\", then the out-degree is exactly preserved, while the in-degree is approximately preseved. Otherwise it's the other way around.</p> Source code in <code>src/connalysis/network/classic.py</code> <pre><code>def generate_degree_based_control(M, direction=\"efferent\"):\n\"\"\"\n    A shuffled version of a connectivity matrix that aims to preserve degree distributions.\n    If direction = \"efferent\", then the out-degree is exactly preserved, while the in-degree is\n    approximately preseved. Otherwise it's the other way around.\n    \"\"\"\n    if direction == \"efferent\":\n        M = M.tocsr()\n        idxx = np.arange(M.shape[1])\n        p_out = np.array(M.mean(axis=0))[0]\n    elif direction == \"afferent\":\n        M = M.tocsc()\n        idxx = np.arange(M.shape[0])\n        p_out = np.array(M.mean(axis=1))[:, 0]\n    else:\n        raise ValueError()\n\n    for col in range(M.shape[1]):\n        p = p_out.copy()\n        p[col] = 0.0\n        p = p / p.sum()\n        a = M.indptr[col]\n        b = M.indptr[col + 1]\n        M.indices[a:b] = np.random.choice(idxx, b - a, p=p, replace=False)\n    return M\n</code></pre>"},{"location":"randomization/","title":"Functions for generating random models","text":"<p>This page describes functions contained in the <code>randomization</code> module used to  generate of randomized controls of connectomes.</p>"},{"location":"randomization/#src.connalysis.randomization.randomization.configuration_model","title":"<code>configuration_model(adj: sp.coo_matrix, seed: int)</code>","text":"<p>Function to generate the configuration control model, obtained by shuffling the row and column of coo format independently, to create new coo matrix, then removing any multiple edges and loops.</p> <p>Parameters:</p> Name Type Description Default <code>adj</code> <code>sp.coo_matrix</code> <p>Adjacency matrix of a directed network.</p> required <code>seed</code> <code>int</code> <p>Random seed to be used</p> required <p>Returns:</p> Type Description <code>csr matrix</code> <p>Configuration model control of adj</p>"},{"location":"randomization/#src.connalysis.randomization.randomization.configuration_model--see-also","title":"See Also","text":"<p>run_SBM: Function which runs the stochastic block model</p> <p>run_DD2 : Function which runs the 2nd distance dependent model</p> Source code in <code>src/connalysis/randomization/randomization.py</code> <pre><code>def configuration_model(adj: sp.coo_matrix, seed: int):\n\"\"\"Function to generate the configuration control model, obtained by\n    shuffling the row and column of coo format independently, to create\n    new coo matrix, then removing any multiple edges and loops.\n\n    Parameters\n    ----------\n    adj: coo-matrix\n        Adjacency matrix of a directed network.\n    seed: int\n        Random seed to be used\n\n    Returns\n    -------\n    csr matrix\n        Configuration model control of adj\n\n    See Also\n    --------\n    run_SBM: Function which runs the stochastic block model\n\n    run_DD2 : Function which runs the 2nd distance dependent model\n    \"\"\"\n    generator = np.random.default_rng(seed)\n    R = adj.row\n    C = adj.col\n    generator.shuffle(R)\n    generator.shuffle(C)\n    CM_matrix = sp.coo_matrix(([1]*len(R),(R,C)),shape=adj.shape).tocsr()\n    CM_matrix.setdiag(0)\n    CM_matrix.eliminate_zeros()\n    return CM_matrix\n</code></pre>"},{"location":"randomization/#src.connalysis.randomization.randomization.run_DD2","title":"<code>run_DD2(n, a, b, xyz, threads = 8, seed = (None, None))</code>","text":"<p>Creates a random digraph using the 2nd-order probability model.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of vertices</p> required <code>a</code> <code>float</code> <p>Coefficient of probability function</p> required <code>b</code> <code>float</code> <p>Absolute value of power of exponent in probability function</p> required <code>xyz</code> <code>(n,3)-numpy array of floats</code> <p>Co-ordinates of vertices in \\(\\mathbb{R}^3\\)</p> required <code>threads</code> <code>int</code> <p>Number of parallel threads to be used</p> <code>8</code> <code>seed</code> <code>pair of ints</code> <p>Random seed to be used, if none is provided a seed is randomly selected</p> <code>(None, None)</code> <p>Returns:</p> Type Description <code>dict</code> <p>The edge list of the new digraph as a dictionary with keys 'row' and 'col'. Where (row[i],col[i]) is a directed edge of the digraph, for all i.</p>"},{"location":"randomization/#src.connalysis.randomization.randomization.run_DD2--see-also","title":"See Also","text":"<p>conn_prob_2nd_order_model : The modelling function from which the parameters <code>a</code> and <code>b</code>can be obtained.</p> Source code in <code>src/connalysis/randomization/randomization.py</code> <pre><code>def run_DD2(n,a,b,xyz,threads=8, seed=(None,None)):\n\"\"\"Creates a random digraph using the 2nd-order probability model.\n\n    Parameters\n    ----------\n    n : int\n        Number of vertices\n    a : float\n        Coefficient of probability function\n    b : float\n        Absolute value of power of exponent in probability function\n    xyz : (n,3)-numpy array of floats\n        Co-ordinates of vertices in $\\mathbb{R}^3$\n    threads : int\n        Number of parallel threads to be used\n    seed : pair of ints\n        Random seed to be used, if none is provided a seed is randomly selected\n\n    Returns\n    -------\n    dict\n        The edge list of the new digraph as a dictionary\n        with keys 'row' and 'col'. Where (row[i],col[i]) is a directed edge\n        of the digraph, for all i.\n\n    See Also\n    --------\n    [conn_prob_2nd_order_model](modelling.md#src.connalysis.modelling.modelling.conn_prob_2nd_order_model) :\n    The modelling function from which the parameters ``a`` and ``b``can be obtained.\n\n\n    \"\"\"\n    if seed[0]==None or seed[1]==None:\n        return gm.DD2(n,a,b,xyz,threads)\n    else:\n        return gm.DD2(n,a,b,xyz,threads,seed[0],seed[1])\n</code></pre>"},{"location":"randomization/#src.connalysis.randomization.randomization.run_DD2_block","title":"<code>run_DD2_block(n, probs, blocks, xyz, threads, seed = (None, None))</code>","text":"<p>Creates a random digraph using a combination of the stochastic block model    and the 2nd order distance dependent model. Such that the probability of an edge    is given by the distance dependent equation, but the parameters of that equation    vary depending on the block of the source of the edge and block of the target.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of vertices</p> required <code>probs</code> <code>numpy array of floats</code> <p>shape=(m,m,2) where m is the number of blocks. For source vertex i and target vertex j probsi[0] is the coefficient of the distance dependent equation (value a) and probsi[0] is the absolute value of power of exponent in the distance dependent equation (value b)</p> required <code>blocks</code> <code>numpy array of ints</code> <p>shape=(n,). The i'th entry is which block vertex i belongs to.</p> required <code>xyz</code> <code>(n,3)-numpy array of floats</code> <p>Co-ordinates of vertices in \\(\\mathbb{R}^3\\)</p> required <code>threads</code> <code>int</code> <p>Number of parallel threads to be used</p> required <code>seed</code> <code>pair of ints</code> <p>Random seed to be used, if none is provided a seed is randomly selected</p> <code>(None, None)</code> <p>Returns:</p> Type Description <code>dict</code> <p>The edge list of the new digraph as a dictionary with keys 'row' and 'col'. Where (row[i],col[i]) is a directed edge of the digraph, for all i.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If blocks contains non-integers</p>"},{"location":"randomization/#src.connalysis.randomization.randomization.run_DD2_block--see-also","title":"See Also","text":"<p>run_DD2 : Function which runs the 2nd distance dependent model</p> <p>run_SBM: Function which runs the stochastic block model</p> <p>run_DD2_block_pre : Similar function that only accounts for the block of the source vertex</p> Source code in <code>src/connalysis/randomization/randomization.py</code> <pre><code>def run_DD2_block(n, probs, blocks, xyz, threads, seed=(None,None)):\n\"\"\"Creates a random digraph using a combination of the stochastic block model\n       and the 2nd order distance dependent model. Such that the probability of an edge\n       is given by the distance dependent equation, but the parameters of that equation\n       vary depending on the block of the source of the edge and block of the target.\n\n    Parameters\n    ----------\n    n : int\n        Number of vertices\n    probs : numpy array of floats\n        shape=(m,m,2) where m is the number of blocks. For source vertex i and target vertex j\n        probs[i][j][0] is the coefficient of the distance dependent equation (value a) and\n        probs[i][j][0] is the absolute value of power of exponent in the distance dependent equation (value b)\n    blocks : numpy array of ints\n        shape=(n,). The i'th entry is which block vertex i belongs to.\n    xyz : (n,3)-numpy array of floats\n        Co-ordinates of vertices in $\\mathbb{R}^3$\n    threads : int\n        Number of parallel threads to be used\n    seed : pair of ints\n        Random seed to be used, if none is provided a seed is randomly selected\n\n    Returns\n    -------\n    dict\n        The edge list of the new digraph as a dictionary\n        with keys 'row' and 'col'. Where (row[i],col[i]) is a directed edge\n        of the digraph, for all i.\n\n\n    Raises\n    ------\n    TypeError\n        If blocks contains non-integers\n\n    See Also\n    --------\n    run_DD2 : Function which runs the 2nd distance dependent model\n\n    run_SBM: Function which runs the stochastic block model\n\n    run_DD2_block_pre : Similar function that only accounts for the block of the source vertex\n\n    \"\"\"\n    if seed[0]==None or seed[1]==None:\n        return gm.DD2_block(n, probs, blocks, xyz, threads)\n    else:\n        return gm.DD2_block(n, probs, blocks, xyz, threads, seed[0], seed[1])\n</code></pre>"},{"location":"randomization/#src.connalysis.randomization.randomization.run_DD2_block_pre","title":"<code>run_DD2_block_pre(n, probs, blocks, xyz, threads = 8, seed = (None, None))</code>","text":"<p>Creates a random digraph using a combination of the stochastic block model    and the 2nd order distance dependent model. Such that the probability of an edge    is given by the distance dependent equation, but the parameters of that equation    vary depending on the block of the source of the edge.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of vertices</p> required <code>probs</code> <code>numpy array of floats</code> <p>shape=(m,2) where m is the number of blocks. probsi is the coefficient of the distance dependent equation (value a) for source vertex i and probsi is the absolute value of power of exponent in the distance dependent equation (value b)</p> required <code>blocks</code> <code>numpy array of ints</code> <p>shape=(n,). The i'th entry is which block vertex i belongs to.</p> required <code>xyz</code> <code>(n,3)-numpy array of floats</code> <p>Co-ordinates of vertices in \\(\\mathbb{R}^3\\)</p> required <code>threads</code> <code>int</code> <p>Number of parallel threads to be used</p> <code>8</code> <code>seed</code> <code>pair of ints</code> <p>Random seed to be used, if none is provided a seed is randomly selected</p> <code>(None, None)</code> <p>Returns:</p> Type Description <code>dict</code> <p>The edge list of the new digraph as a dictionary with keys 'row' and 'col'. Where (row[i],col[i]) is a directed edge of the digraph, for all i.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If blocks contains non-integers</p>"},{"location":"randomization/#src.connalysis.randomization.randomization.run_DD2_block_pre--see-also","title":"See Also","text":"<p>run_SBM: Function which runs the stochastic block model</p> <p>run_DD2 : Function which runs the 2nd distance dependent model</p> <p>run_DD2_block : Similar function that also accounts for the block of the target vertex</p> Source code in <code>src/connalysis/randomization/randomization.py</code> <pre><code>def run_DD2_block_pre(n, probs, blocks, xyz, threads=8, seed=(None,None)):\n\"\"\"Creates a random digraph using a combination of the stochastic block model\n       and the 2nd order distance dependent model. Such that the probability of an edge\n       is given by the distance dependent equation, but the parameters of that equation\n       vary depending on the block of the source of the edge.\n\n    Parameters\n    ----------\n    n : int\n        Number of vertices\n    probs : numpy array of floats\n        shape=(m,2) where m is the number of blocks.\n        probs[i][0] is the coefficient of the distance dependent equation (value a) for source vertex i and\n        probs[i][0] is the absolute value of power of exponent in the distance dependent equation (value b)\n    blocks : numpy array of ints\n        shape=(n,). The i'th entry is which block vertex i belongs to.\n    xyz : (n,3)-numpy array of floats\n        Co-ordinates of vertices in $\\mathbb{R}^3$\n    threads : int\n        Number of parallel threads to be used\n    seed : pair of ints\n        Random seed to be used, if none is provided a seed is randomly selected\n\n    Returns\n    -------\n    dict\n        The edge list of the new digraph as a dictionary\n        with keys 'row' and 'col'. Where (row[i],col[i]) is a directed edge\n        of the digraph, for all i.\n\n\n    Raises\n    ------\n    TypeError\n        If blocks contains non-integers\n\n    See Also\n    --------\n    run_SBM: Function which runs the stochastic block model\n\n    run_DD2 : Function which runs the 2nd distance dependent model\n\n    run_DD2_block : Similar function that also accounts for the block of the target vertex\n\n    \"\"\"\n\n    if seed[0]==None or seed[1]==None:\n        return gm.DD2_block_pre(n, probs, blocks, xyz, threads)\n    else:\n        gm.DD2_block_pre(n, probs, blocks, xyz, threads, seed[0], seed[1])\n</code></pre>"},{"location":"randomization/#src.connalysis.randomization.randomization.run_DD2_model","title":"<code>run_DD2_model(adj, node_properties, model_params_dd2 = None, coord_names = ['x', 'y', 'z'], threads = 8, return_params = False, **config_dict)</code>","text":"<p>Wrapper generating a random control graph based on 2nd order distance dependence model Input: adj: original adjacency matrix, if model_params have already been computed can pass empty matrix of the right size node_properties: DataFrame with information on the vertices of adj, it must have columns corresponding to the names the coordinates to be used for distance computation.  Default ['x', 'y', 'z'] configdict: Add me --&gt; to generate parameters of 2nd order distance model model_params: optional input of pre-computed model parameters, data frame with rows corresponding to seeds of model estimation (single row if subsampling is not used) and columns: exp_model_scale and exp_model_exponent for the model parameters.  See modelling.conn_prob_2nd_order_model for details.</p> <p>Output: scipy coo matrix, optional model_parameters</p> Source code in <code>src/connalysis/randomization/randomization.py</code> <pre><code>def run_DD2_model(adj, node_properties,\n                  model_params_dd2=None, #an analysis that could be loaded from the pipeline\n                  coord_names= ['x', 'y', 'z'],\n                  threads=8, return_params=False, **config_dict):\n\"\"\"\n    Wrapper generating a random control graph based on 2nd order distance dependence model\n    Input:\n    adj: original adjacency matrix, if model_params have already been computed can pass empty matrix of the right size\n    node_properties: DataFrame with information on the vertices of adj, it must have columns corresponding to the names\n    the coordinates to be used for distance computation.  Default ['x', 'y', 'z']\n    configdict: Add me --&gt; to generate parameters of 2nd order distance model\n    model_params: optional input of pre-computed model parameters, data frame with rows corresponding to seeds of model estimation\n    (single row if subsampling is not used) and columns:\n    exp_model_scale and exp_model_exponent for the model parameters.  See modelling.conn_prob_2nd_order_model for details.\n\n    Output: scipy coo matrix, optional model_parameters\n    \"\"\"\n\n    if model_params_dd2 is None:\n        from .import modelling\n        #TODO:  What to do if coord_names are also given in configdict and do not match coord_names?\n        config_dict[\"coord_names\"]=coord_names\n        model_params_dd2 = modelling.conn_prob_2nd_order_model(adj, node_properties,**config_dict)\n\n    LOG.info(\"Run DD2 model with parameters: \\n%s\", model_params_dd2)\n\n    n = adj.shape[0]\n    a = model_params_dd2.mean(axis=0)['exp_model_scale']\n    b = model_params_dd2.mean(axis=0)['exp_model_exponent']\n    xyz = node_properties.loc[:,coord_names].to_numpy() #Make and assert that checks these columns exist!\n    if len(coord_names)&lt;3: #Extend by zeros if lower dimensional data was used to compute distance\n        xyz=np.hstack([xyz,np.zeros((xyz.shape[0],3-xyz.shape[1]))])\n    C=gm.DD2(n,a,b,xyz,threads)\n    i=C['row']\n    j=C['col']\n    data=np.ones(len(i))\n    if return_params==True:\n        return sp.coo_matrix((data, (i, j)), [n,n]), model_params_dd2\n    else:\n        return sp.coo_matrix((data, (i, j)), [n,n])\n</code></pre>"},{"location":"randomization/#src.connalysis.randomization.randomization.run_DD3","title":"<code>run_DD3(n, a1, b1, a2, b2, xyz, depths, threads = 8, seed = (None, None))</code>","text":"<p>Creates a random digraph using the 2nd-order probability model.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of vertices</p> required <code>a1</code> <code>float</code> <p>Coefficient of probability function for negative depth</p> required <code>b1</code> <code>float</code> <p>Absolute value of power of exponent in probability function for negative depth</p> required <code>a2</code> <code>float</code> <p>Coefficient of probability function for positive depth</p> required <code>b2</code> <code>float</code> <p>Absolute value of power of exponent in probability function for positive depth</p> required <code>xyz</code> <code>(n,3)-numpy array of floats</code> <p>Co-ordinates of vertices in \\(\\mathbb{R}^3\\)</p> required <code>threads</code> <code>int</code> <p>Number of parallel threads to be used</p> <code>8</code> <code>seed</code> <code>pair of ints</code> <p>Random seed to be used, if none is provided a seed is randomly selected</p> <code>(None, None)</code> <p>Returns:</p> Type Description <code>dict</code> <p>The edge list of the new digraph as a dictionary with keys 'row' and 'col'. Where (row[i],col[i]) is a directed edge of the digraph, for all i.</p>"},{"location":"randomization/#src.connalysis.randomization.randomization.run_DD3--see-also","title":"See Also","text":"<p>conn_prob_3rd_order_model : The modelling function from which the parameters <code>a1/a2</code> and <code>b1/b2</code>can be obtained.</p> Source code in <code>src/connalysis/randomization/randomization.py</code> <pre><code>def run_DD3(n,a1,b1,a2,b2,xyz,depths,threads=8, seed=(None,None)):\n\"\"\"Creates a random digraph using the 2nd-order probability model.\n\n    Parameters\n    ----------\n    n : int\n        Number of vertices\n    a1 : float\n        Coefficient of probability function for negative depth\n    b1 : float\n        Absolute value of power of exponent in probability function for negative depth\n    a2 : float\n        Coefficient of probability function for positive depth\n    b2 : float\n        Absolute value of power of exponent in probability function for positive depth\n    xyz : (n,3)-numpy array of floats\n        Co-ordinates of vertices in $\\mathbb{R}^3$\n    threads : int\n        Number of parallel threads to be used\n    seed : pair of ints\n        Random seed to be used, if none is provided a seed is randomly selected\n\n    Returns\n    -------\n    dict\n        The edge list of the new digraph as a dictionary\n        with keys 'row' and 'col'. Where (row[i],col[i]) is a directed edge\n        of the digraph, for all i.\n\n\n    See Also\n    --------\n    [conn_prob_3rd_order_model](modelling.md#src.connalysis.modelling.modelling.conn_prob_3rd_order_model) :\n    The modelling function from which the parameters ``a1/a2`` and ``b1/b2``can be obtained.\n\n\n\n    \"\"\"\n    if seed[0]==None or seed[1]==None:\n        return gm.DD3(n,a1,b1,a2,b2,xyz,depths,threads)\n    else:\n        return gm.DD3(n,a1,b1,a2,b2,xyz,depths,threads,seed[0],seed[1])\n</code></pre>"},{"location":"randomization/#src.connalysis.randomization.randomization.run_ER","title":"<code>run_ER(n, p, threads = 8, seed = (None, None))</code>","text":"<p>Creates an Erdos Renyi digraph.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of vertices</p> required <code>p</code> <code>float</code> <p>Edge probablity, must satisfy \\(0 \\le p \\le 1\\)</p> required <code>threads</code> <code>int</code> <p>Number of parallel threads to be used</p> <code>8</code> <code>seed</code> <code>pair of ints</code> <p>Random seed to be used, if none is provided a seed is randomly selected</p> <code>(None, None)</code> <p>Returns:</p> Type Description <code>dict</code> <p>The edge list of the new digraph as a dictionary with keys 'row' and 'col'. Where (row[i],col[i]) is a directed edge of the digraph, for all i.</p> <p>Examples:</p> <p>Setting n=3 and p=1 gives the complete digraph on 3 vertices:</p> <pre><code>&gt;&gt;&gt; connalysis.randomization.run_ER(3,1)\n{'row': [0, 0, 1, 1, 2, 2], 'col': [1, 2, 0, 2, 0, 1]}\n</code></pre> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If p is not between 0 and 1</p> Source code in <code>src/connalysis/randomization/randomization.py</code> <pre><code>def run_ER(n, p, threads=8, seed=(None,None)):\n\"\"\"Creates an Erdos Renyi digraph.\n\n    Parameters\n    ----------\n    n : int\n        Number of vertices\n    p : float\n        Edge probablity, must satisfy $0 \\\\le p \\\\le 1$\n    threads : int\n        Number of parallel threads to be used\n    seed : pair of ints\n        Random seed to be used, if none is provided a seed is randomly selected\n\n    Returns\n    -------\n    dict\n        The edge list of the new digraph as a dictionary\n        with keys 'row' and 'col'. Where (row[i],col[i]) is a directed edge\n        of the digraph, for all i.\n\n    Examples\n    --------\n    Setting n=3 and p=1 gives the complete digraph on 3 vertices:\n    &gt;&gt;&gt; connalysis.randomization.run_ER(3,1)\n    {'row': [0, 0, 1, 1, 2, 2], 'col': [1, 2, 0, 2, 0, 1]}\n\n    Raises\n    ------\n    AssertionError\n        If p is not between 0 and 1\n\n    \"\"\"\n    assert (p &gt;= 0 and p &lt;= 1), \"p must be between 0 and 1\"\n    if seed[0]==None or seed[1]==None:\n        return gm.ER(n,p,threads)\n    else:\n        return gm.ER(n,p,threads,seed[0],seed[1])\n</code></pre>"},{"location":"randomization/#src.connalysis.randomization.randomization.run_SBM","title":"<code>run_SBM(n, probs, blocks, threads = 8, seed = (None, None))</code>","text":"<p>Creates a random digraph using the stochastic block model.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of vertices</p> required <code>probs</code> <code>numpy array of floats</code> <p>shape=(m,m) where m is the number of blocks. probsi is probability of an edge between block i and block j</p> required <code>blocks</code> <code>numpy array of ints</code> <p>shape=(n,). The i'th entry gives to which block vertex i belongs.</p> required <code>threads</code> <code>int</code> <p>Number of parallel threads to be used</p> <code>8</code> <code>seed</code> <code>pair of ints</code> <p>Random seed to be used, if none is provided a seed is randomly selected</p> <code>(None, None)</code> <p>Returns:</p> Type Description <code>dict</code> <p>The edge list of the new digraph as a dictionary with keys 'row' and 'col'. Where (row[i],col[i]) is a directed edge of the digraph, for all i.</p> <p>Examples:</p> <p>To create an SBM digraph on 4 vertices where the even to odd, or odd to even, vertices connect with high probablity (p=0.9) and the even to evens or odd to odds connect with low probability (p=0.1):</p> <pre><code>&gt;&gt;&gt; connalysis.randomization.run_SBM(4,np.array([[0.1,0.9],[0.9,0.1]]),np.array([0,1,0,1]))\n{'row': [0, 0, 1, 1, 1, 2, 2, 3, 3], 'col': [1, 3, 0, 2, 3, 1, 3, 0, 2]\n</code></pre> <p>Raises:</p> Type Description <code>TypeError</code> <p>If blocks contains non-integers</p>"},{"location":"randomization/#src.connalysis.randomization.randomization.run_SBM--references","title":"References","text":"<p>[1] P.W. Holland, K. Laskey, S. Leinhardt, \"Stochastic Blockmodels: First Steps\", Soc Networks, 5-2, pp. 109-137, 1982</p> Source code in <code>src/connalysis/randomization/randomization.py</code> <pre><code>def run_SBM(n, probs, blocks, threads=8, seed=(None,None)):\n\"\"\"Creates a random digraph using the stochastic block model.\n\n    Parameters\n    ----------\n    n : int\n        Number of vertices\n    probs : numpy array of floats\n        shape=(m,m) where m is the number of blocks.\n        probs[i][j] is probability of an edge between block i and block j\n    blocks : numpy array of ints\n        shape=(n,). The i'th entry gives to which block vertex i belongs.\n    threads : int\n        Number of parallel threads to be used\n    seed : pair of ints\n        Random seed to be used, if none is provided a seed is randomly selected\n\n    Returns\n    -------\n    dict\n        The edge list of the new digraph as a dictionary\n        with keys 'row' and 'col'. Where (row[i],col[i]) is a directed edge\n        of the digraph, for all i.\n\n    Examples\n    --------\n    To create an SBM digraph on 4 vertices where the even to\n    odd, or odd to even, vertices connect with high probablity (p=0.9)\n    and the even to evens or odd to odds connect with low probability (p=0.1):\n    &gt;&gt;&gt; connalysis.randomization.run_SBM(4,np.array([[0.1,0.9],[0.9,0.1]]),np.array([0,1,0,1]))\n    {'row': [0, 0, 1, 1, 1, 2, 2, 3, 3], 'col': [1, 3, 0, 2, 3, 1, 3, 0, 2]\n\n\n    Raises\n    ------\n    TypeError\n        If blocks contains non-integers\n\n    References\n    ----------\n    [1] P.W. Holland, K. Laskey, S. Leinhardt,\n    [\"Stochastic Blockmodels: First Steps\"](https://www.sciencedirect.com/science/article/pii/0378873383900217),\n    Soc Networks, 5-2, pp. 109-137, 1982\n\n    \"\"\"\n\n    if seed[0]==None or seed[1]==None:\n        return gm.SBM(n, probs, blocks, threads)\n    else:\n        return gm.SBM(n, probs, blocks, threads, seed[0], seed[1])\n</code></pre>"}]}